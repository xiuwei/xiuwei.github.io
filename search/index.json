[{"content":" # RESTful API 介绍 在回答“RESTful API 是什么”之前，我们先来看下 REST 是什么意思：REST 代表的是表现层状态转移（REpresentational State Transfer），由 Roy Fielding 在他的论文《Architectural Styles and the Design of Network-based Software Architectures》里提出。REST 本身并没有创造新的技术、组件或服务，它只是一种软件架构风格，是一组架构约束条件和原则，而不是技术框架。\nREST 有一系列规范，满足这些规范的 API 均可称为 RESTful API。REST 规范把所有内容都视为资源，也就是说网络上一切皆资源。REST 架构对资源的操作包括获取、创建、修改和删除，这些操作正好对应 HTTP 协议提供的 GET、POST、PUT 和 DELETE 方法。\nREST 风格虽然适用于很多传输协议，但在实际开发中，由于 REST 天生和 HTTP 协议相辅相成，因此 HTTP 协议已经成了实现 RESTful API 事实上的标准。所以，REST 具有以下核心特点：\n以资源（resource）为中心，所有的东西都抽象成资源，所有的行为都应该是在资源上的 CRUD 操作。 资源对应着面向对象范式里的对象，面向对象范式以对象为中心。 资源使用 URI 标识，每个资源实例都有一个唯一的 URI 标识。例如，如果我们有一个用户，用户名是 admin，那么它的 URI 标识就可以是 /users/admin。 资源是有状态的，使用 JSON/XML 等在 HTTP Body 里表征资源的状态。 客户端通过四个 HTTP 动词，对服务器端资源进行操作，实现“表现层状态转化”。 无状态，这里的无状态是指每个 RESTful API 请求都包含了所有足够完成本次操作的信息，服务器端无须保持 session。无状态对于服务端的弹性扩容是很重要的。 提示：因为怕你弄混概念，这里强调下 REST 和 RESTful API 的区别：REST 是一种规范，而 RESTful API 则是满足这种规范的 API 接口。\n# RESTful API 设计原则 上面我们说了，RESTful API 就是满足 REST 规范的 API，由此看来，RESTful API 的核心是规范，那么具体有哪些规范呢？\n接下来从 URI 设计、API 版本管理等七个方面，详细介绍 RESTful API 的设计原则。\n# URI 设计 资源都是使用 URI 标识的，我们应该按照一定的规范来设计 URI，通过规范化可以使我们的 API 接口更加易读、易用。以下是 URI 设计时，应该遵循的一些规范：\n资源名使用名词而不是动词，并且用名词复数表示。资源分为 Collection 和 Member 两种。 Collection：一堆资源的集合。例如我们系统里有很多用户（User），这些用户的集合就是 Collection。Collection 的 URI 标识应该是 域名/资源名复数， 例如 example.com/v1/users。 Member：单个特定资源。例如系统中特定名字的用户，就是 Collection 里的一个 Member。Member 的 URI 标识应该是 域名/资源名复数/资源名称， 例如 example.com/v1/users/colin。 URI 结尾不应包含 / 。 URI 中不能出现下划线 _，必须用中杠线 - 代替（有些人推荐用 _，有些人推荐用 -，统一使用一种格式即可，我比较推荐用 -）。 URI 路径用小写，不要用大写。 避免层级过深的 URI。超过 2 层的资源嵌套会很乱，建议将其他资源转化为 ? 参数，比如： 1 2 /schools/qinghua/classes/rooma/students/colin # 不推荐 /students?school=qinghua\u0026amp;class=rooma # 推荐 这里有个地方需要注意：在实际的 API 开发中，可能你会发现有些操作不能很好地映射为一个 REST 资源，这时候，你可以参考下面的做法。\n将一个操作变成资源的一个属性，比如想在系统中暂时禁用某个用户，可以这么设计 URI：/users/colin?active=false。 将操作当作是一个资源的嵌套资源，比如一个 GitHub 的加星操作： 1 2 PUT /gists/:id/star # github star action DELETE /gists/:id/star # github unstar action 如果以上都不能解决问题，有时可以打破这类规范。比如登录操作，登录不属于任何一个资源，URI 可以设计为：/v1/login。\n在设计 URI 时，如果你遇到一些不确定的地方，推荐你参考 GitHub 标准 RESTful API。\n# REST 资源操作映射为 HTTP 方法 基本上 RESTful API 都是使用 HTTP 协议原生的 GET、PUT、POST、DELETE 来标识对资源的 CRUD 操作，形成的规范如下表所示：\nHTTP 方法 Collection 资源（/v1/users） Ember 资源（/v1/users/:username） GET 获取一个 Collection 下所有的 Member 信息 获取一个 Member 的状态表征 POST 在 Collection 中新建一个 Member 没有这类操作 PUT 用另外一个 Collection 替换这个 Collection 更新一个 Member 的状态表征 DELETE 删除整个 Collection，可以用来批量删除资源 删除这个 Member 提示：Collection 代表资源集合，Ember 代表特定的资源。\n下面是一个具体的映射例子：\nHTTP 方法 行为 URI 示例说明 GET 获取资源列表 /users 获取用户列表 GET 获取一个具体的资源表述 /users/colin 获取colin用户的详细信息 POST 创建一个新的资源 /users 创建一个新的用户 PUT 更新一个资源 /users/colin 更新用户名为colin的用户 DELET 删除服务器上的一个资源 /users/colin 删除用户名为colin的用户 GET、PUT、POST、DELETE 是 RESTful API 最常用的 HTTP 请求方法。HTTP 还提供了另外 3 种请求方法，这些方法不经常使用，这里也列举出来供你参考：\nHTTP 方法 Collection 资源（/v1/users） Ember 资源（/v1/users/:username） PATCH 整个 Collection 进行部分更新，通常用于更新 Collection 的某些属性或字段 获取一个 Member 的元信息 HEAD 获取一个 Collection 的元信息，但不需要获取实际资源的内容 获取 Member 的元信息，但不需要获取实际资源的内容 OPTIONS 获取整个 Collection 支持的通信选项，比如支持的 HTTP 方法、请求头等信息 获取 Member 支持的通信选项，包括支持的 HTTP 方法、请求头等信息 提示：OPTIONS 请求方法通常用于跨域请求时的预检请求。\n对资源的操作应该满足安全性和幂等性：\n安全性：不会改变资源状态，可以理解为只读的。 幂等性：执行 1 次和执行 N 次，对资源状态改变的效果是等价的。 使用不同 HTTP 方法时，资源操作的安全性和幂等性对照见下表：\nHTTP 方法 是否安全 是否幂等 GET 是 是 POST 否 否 PUT 否 是 DELETE 否 是 PATCH 否 是 HEAD 是 是 OPTIONS 是 是 在使用 HTTP 方法的时候，有以下两点需要你注意：\nGET 返回的结果，要尽量可用于 PUT、POST 操作中。例如，用 GET 方法获得了一个 user 的信息，调用者修改 user 的邮件，然后将此结果再用 PUT 方法更新。这要求 GET、PUT、POST 操作的资源属性类型是一样的。 如果对资源进行状态/属性变更，要用 PUT 方法，POST 方法仅用来创建或者批量删除这两种场景。 在设计 API 时，经常会有批量删除的需求，需要在请求中携带多个需要删除的资源名，但是 HTTP 的 DELETE 方法不能携带多个资源名，这时候可以通过下面三种方式来解决：\n发起多个 DELETE 请求。 操作路径中带多个 id，id 之间用分隔符分隔， 例如：DELETE /v1/users?ids=1,2,3 。 直接使用 POST 方式来批量删除，Body 中传入需要删除的资源列表。 其中，第二种是我最推荐的方式，因为使用了匹配的 DELETE 动词，并且不需要发送多次 DELETE 请求。这时候，你可能会问如果 id 列表太长，会不会有性能问题？其实不会的，因为在一个真实的项目中，我们每次允许删除的条目个数是有限的，每次最大删除的条目数，通常跟每个页面的最大展示条数保持一致。\n你需要注意的是，这三种方式都有各自的使用场景，你可以根据需要自行选择。如果选择了某一种方式，那么整个项目都需要统一用这种方式。\n# 匹配 HTTP 请求方法的参数 HTTP 有很多请求方法，例如：GET、PUT、POST、DELETE 等。在执行 HTTP 请求时，根据请求方法的类型，其参数指定位置也是有规范。在执行请求时，HTTP 请求方法和请求参数不匹配的请求，客户端会报错或者拒绝请求。\nHTTP 请求参数，可以视情况设置在以下位置：\n查询参数（Query Parameters）：查询参数是附加在 URL 路径后面的键值对，使用 ? 开头，多个参数之间使用 \u0026amp; 分隔，例如：http://example.com/api/resource?param1=value1\u0026amp;param2=value2。查询参数通常用于对资源进行过滤、分页、排序等操作； 路径参数（Path Parameters）：路径参数是出现在 URL 路径中的一部分，通常用花括号 {} 包裹，例如：http://example.com/api/resource/{id}。路径参数用于标识资源的唯一标识符或者其他需要在 URL 中直接体现的参数； 请求头（Request Headers）：请求头是包含在 HTTP 请求头部中的键值对，例如：Content-Type: application/json。请求头用于传递请求的元数据、授权信息、内容类型等； 请求体（Request Body）：请求体是包含在 HTTP 请求中的主体部分，通常用于 POST、PUT、PATCH 等方法中传递数据。请求体用于传递请求的具体数据，通常使用 JSON、XML 等格式； Cookie：Cookie 是存储在客户端的一小段文本信息，会随着每次请求被发送到服务器。Cookie 用于在客户端和服务器之间保持状态，通常用于会话管理、用户认证等。 下表是不同 HTTP 请求方法所支持的请求参数的设置位置：\n请求方法 参数位置 GET 适配的请求参数位置：查询参数（Query Parameters）和路径参数（Path Parameters）；GET 请求通常通过查询参数传递参数，也可以通过路径参数传递需要标识的资源。 POST 适配的请求参数位置：请求体（Request Body）；POST 请求通常通过请求体传递需要创建的资源的数据。 PUT 适配的请求参数位置：路径参数（Path Parameters）和请求体（Request Body）；PUT 请求通常通过路径参数指定要更新的资源，通过请求体传递更新后的数据。 DELETE 适配的请求参数位置：路径参数（Path Parameters）；DELETE 请求通常通过路径参数指定要删除的资源。 PATCH 适配的请求参数位置：路径参数（Path Parameters）和请求体（Request Body）；PATCH 请求通常通过路径参数指定要部分更新的资源，通过请求体传递更新的部分数据。 HEAD 适配的请求参数位置：查询参数（Query Parameters）和路径参数（Path Parameters）；HEAD 请求通常通过查询参数和路径参数传递参数，用于获取资源的元信息而不获取资源本身。 OPTIONS 适配的请求参数位置：无特定参数位置要求；OPTIONS 请求通常用于获取目标资源所支持的通信选项，不需要特定的请求参数位置。 # 统一的返回格式 一般来说，一个系统的 RESTful API 会向外界开放多个资源的接口，每个接口的返回格式要保持一致。另外，每个接口都会返回成功和失败两种消息，这两种消息的格式也要保持一致。不然，客户端代码要适配不同接口的返回格式，每个返回格式又要适配成功和失败两种消息格式，会大大增加用户的学习和使用成本。返回的格式没有强制的标准，你可以根据实际的业务需要返回不同的格式。\n# API 版本管理 随着时间的推移、需求的变更，一个 API 往往满足不了现有的需求，这时候就需要对 API 进行修改。对 API 进行修改时，不能影响其他调用系统的正常使用，这就要求 API 变更做到向下兼容，也就是新老版本共存。\n但在实际场景中，很可能会出现同一个 API 无法向下兼容的情况。这时候最好的解决办法是从一开始就引入 API 版本机制，当不能向下兼容时，就引入一个新的版本，老的版本则保留原样。这样既能保证服务的可用性和安全性，同时也能满足新需求。\nAPI 版本有不同的标识方法，在 RESTful API 开发中，通常将版本标识放在如下 3 个位置：\nURL 中，比如 /v1/users。 HTTP Header 中，比如 Accept: vnd.example-com.foo+json; version=1.0。 Form 参数中，比如 /users?version=v1。 通常建议将版本标识放在 URL 中的，比如 /v1/users，这样做的好处是很直观，GitHub、Kubernetes、Etcd 等很多优秀的 API 均采用这种方式。\n这里要注意，有些开发人员不建议将版本放在 URL 中，因为他们觉得不同的版本可以理解成同一种资源的不同表现形式，所以应该采用同一个 URI。对于这一点，没有严格的标准，根据项目实际需要选择一种方式即可。\n# API 命名 API 通常的命名方式有三种，分别是驼峰命名法（serverAddress）、蛇形命名法（server_address）和脊柱命名法（server-address）。\n驼峰命名法和蛇形命名法都需要切换输入法，会增加操作的复杂性，也容易出错，所以这里建议用脊柱命名法。GitHub API 用的就是脊柱命名法，例如 selected-actions。\n# 统一分页/过滤/排序/搜索功能 REST 资源的查询接口，通常情况下都需要实现分页、过滤、排序、搜索功能，因为这些功能是每个 REST 资源都能用到的，所以可以实现为一个公共的 API 组件。下面来介绍下这些功能。\n分页：在列出一个 Collection 下所有的 Member 时，应该提供分页功能，例如 /users?offset=0\u0026amp;limit=20（limit，指定返回记录的数量；offset，指定返回记录的开始位置）。引入分页功能可以减少 API 响应的延时，同时可以避免返回太多条目，导致服务器/客户端响应特别慢，甚至导致服务器/客户端 crash 的情况。 过滤：如果用户不需要一个资源的全部状态属性，可以在 URI 参数里指定返回哪些属性，例如 /users?fields=email,username,address。 排序：用户很多时候会根据创建时间或者其他因素，列出一个 Collection 中前 100 个 Member，这时可以在 URI 参数中指明排序参数，例如 /users?sort=age,desc。 搜索：当一个资源的 Member 太多时，用户可能想通过搜索，快速找到所需要的 Member，或着想搜下有没有名字为 xxx 的某类资源，这时候就需要提供搜索功能。搜索建议按模糊匹配来搜索。 # 域名 API 的域名设置主要有两种方式：\nhttps://example.com/api，这种方式适合 API 将来不会有进一步扩展的情况，比如刚开始 example.com 域名下只有一套 API 系统，未来也只有这一套 API 系统。 https://xxx.api.example.com，如果 example.com 域名下未来会新增另一个系统 API，这时候最好的方式是每个系统的 API 拥有专有的 API 域名，比如：storage.api.example.com，network.api.example.com。腾讯云的域名就是采用这种方式。 到这里，我们就将 REST 设计原则中的核心原则讲完了，这里有个需要注意的点：不同公司、不同团队、不同项目可能采取不同的 REST 设计原则，以上所列的基本上都是大家公认的原则。\nREST 设计原则中，还有一些原则因为内容比较多，并且可以独立成模块，所以放在后面来讲。比如 RESTful API 安全性、状态返回码、认证等。\n# 总结 本文详细介绍了 RESTful API 及 RESTful API 设计原则。REST 是一种 API 规范，而 RESTful API 则是满足这种规范的 API 接口，RESTful API 的核心是规范。\n在 REST 规范中，资源通过 URI 来标识，资源名使用名词而不是动词，并且用名词复数表示，资源都是分为 Collection 和 Member 两种。RESTful API 中，分别使用 POST 、 DELETE 、 PUT 、 GET 来表示 REST 资源的增删改查，HTTP 方法、Collection、Member 不同组合会产生不同的操作，具体的映射你可以看下 REST 资源操作映射为 HTTP 方法 部分的表格。\n为了方便用户使用和理解，每个 RESTful API 的返回格式、错误和正确消息的返回格式，都应该保持一致。RESTful API 需要支持 API 版本，并且版本应该能够向前兼容，我们可以将版本号放在 URL 中、HTTP Header 中、Form 参数中，但这里我建议将版本号放在 URL 中，例如 /v1/users，这种形式比较直观。\n另外，我们可以通过脊柱命名法来命名 API 接口名。对于一个 REST 资源，其查询接口还应该支持分页/过滤/排序/搜索功能，这些功能可以用同一套机制来实现。 API 的域名可以采用 https://example.com/api 和 https://xxx.api.example.com 两种格式。\n","date":"2024-05-05T19:00:00Z","image":"https://xiuwei.github.io/p/rest-specification/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_952087_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/rest-specification/","title":"REST 接口规范"},{"content":" # 1. 引言 在云原生应用开发中，健康检查是确保微服务可靠性和稳定性的关键环节。特别是在 Kubernetes 这样的容器编排平台上，通过健康检查可以有效地监控和管理应用程序的状态，及时发现并处理潜在的故障情况，从而确保整个系统的正常运行。\n而 Spring Boot 作为一种流行的 Java 微服务框架，其在 Kubernetes 上的部署和健康检查配置也是开发者们关注的焦点。本文将针对这一问题，提供一套完整的实战指南，帮助读者深入了解在 Kubernetes 环境中部署 Spring Boot 微服务并实施健康检查的步骤和方法。\n# 2. 原理 # 2.1 Kubernetes健康检查机制 Kubernetes中的健康检查主要使用 就绪性探针 readinessProbe 、存活性探针 livenessProbe 和启动探针 startupProbe 来实现，service即为负载均衡，k8s保证 service 后面的 pod 都可用，是k8s中自愈能力的主要手段，主要基于这两种探测机制，可以实现如下需求：\n异常实例自动剔除，并重启新实例。 多种类型探针检测，保证异常pod不接入流量。 不停机部署，更安全的滚动升级。 # 2.1.1 探针类型 针对运行中的容器，kubelet 可以选择是否执行以下三种探针，以及如何针对探测结果作出反应：\nlivenessProbe: 指示容器是否正在运行。如果存活态探测失败，则 kubelet 会杀死容器， 并且容器将根据其重启策略进行重启。如果容器不提供存活探针，则默认状态为 Success。 readinessProbe: 指示容器是否准备好为请求提供服务。如果就绪态探测失败， 端点控制器将从与 Pod 匹配的所有服务的端点列表中删除该 Pod 的 IP 地址。初始延迟之前的就绪态的状态值默认为 Failure。 如果容器不提供就绪态探针，则默认状态为 Success。 startupProbe: 指示容器中的应用是否已经启动。如果提供了启动探针，则所有其他探针都会被 禁用，直到此探针成功为止。如果启动探测失败，kubelet 将杀死容器，而容器依其重启策略进行重启。 如果容器没有提供启动探测，则默认状态为 Success。 # 2.1.2 探针结果 每次探测都将获得以下三种结果之一：\nSuccess（成功）: 容器通过了诊断。 Failure（失败）: 容器未通过诊断。 Unknown（未知）: 诊断失败，因此不会采取任何行动。 # 2.1.3 探针检查机制 使用探针来检查容器有四种不同的方法。 每个探针都必须准确定义为这四种机制中的一种：\nexec： 在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。 grpc： 使用 gRPC 执行一个远程过程调用。 目标应该实现 gRPC 健康检查。 如果响应的状态是 \u0026ldquo;SERVING\u0026rdquo;，则认为诊断成功。 httpGet： 对容器的 IP 地址上指定端口和路径执行 HTTP GET 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的。 tcpSocket： 对容器的 IP 地址上的指定端口执行 TCP 检查。如果端口打开，则诊断被认为是成功的。 如果远程系统（容器）在打开连接后立即将其关闭，这算作是健康的。 # 2.2 Spring Boot对Kubernetes容器探针的支持 Spring Boot 2.3 版本引入了容器探针功能，其中包括了 /actuator/health/liveness 和 /actuator/health/readiness 这两个健康检查路径。这些路径是为了更好地支持部署在 Kubernetes 等容器环境中的应用程序。\n/actuator/health/liveness 用于存活性检查，用于确定应用程序是否仍然在运行。 /actuator/health/readiness 用于就绪性检查，用于确定应用程序是否准备好接收流量。 Spring Boot Actuator 会自动将这两个路径暴露出来，并通过它们来执行相应的健康检查。这样，当你在 Kubernetes 中部署 Spring Boot 应用程序时，Kubernetes 可以利用这些路径来确定容器是否健康和准备好接收流量。\n这种集成简化了在 Kubernetes 中部署 Spring Boot 应用程序的流程，并提高了应用程序的可靠性和可用性。\n# 2.2.1 Spring Boot 如何识别k8s环境 Spring Boot 通过检查环境中的 \u0026quot;*_SERVICE_HOST\u0026quot; 和 \u0026quot;*_SERVICE_PORT\u0026quot; 变量来自动检测 Kubernetes 部署环境。也可以使用 spring.main.cloud-platform 配置属性覆盖此检测。\nSpring Boot 识别到 Kubernetes 环境后，Spring Boot Actuator 会自动将/actuator/health/liveness 和 /actuator/health/readiness这两个端点暴露出来。\n小技巧：本地验证这一特性可以通过手动设置 KUBERNETES_SERVICE_HOST 和 KUBERNETES_SERVICE_PORT 这两个环境变量来开启存活和就绪检查。访问 http://localhost:8080/actuator/health/liveness 响应200状态码时代表已开启。\n# 2.2.2 Spring Boot 与k8s容器探针的结合 默认情况下，Spring Boot 管理应用程序可用性状态。如果部署在 Kubernetes 环境中，Actuator 会从收集“Liveness”和“Readiness”信息，并将该信息用于各类专用的 HealthIndicators。\nKubernetes 存活与就绪检查配置示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 livenessProbe: httpGet: path: \u0026#34;/actuator/health/liveness\u0026#34; port: \u0026lt;actuator-port\u0026gt; failureThreshold: ... periodSeconds: ... readinessProbe: httpGet: path: \u0026#34;/actuator/health/readiness\u0026#34; port: \u0026lt;actuator-port\u0026gt; failureThreshold: ... periodSeconds: ... 应设置为 actuator endpoints 的端口。它可能是 Web 服务器端口或为 Actuator 单独设置的端口。通过 \u0026ldquo;management.server.port\u0026rdquo; 配置指定。\n# 2.2.3 Spring Boot 生命周期与探测状态 Kubernetes Probes 支持的一个重要方面是它与应用程序生命周期的一致性。（应用程序的内存中内部状态）和实际探针（公开该状态）之间存在显着差异。根据应用程序生命周期的阶段，探测器可能不可用。\nSpring Boot 在启动和关闭期间发布 Application Events，探测器可以监听此类事件并暴露 AvailabilityState 信息。\n下表显示了AvailabilityState和HTTP连接器在不同阶段的状态。\n当 Spring Boot 应用程序启动时： 当 Spring Boot 应用程序 关闭时: # 3. 准备工作 在开始部署 Spring Boot 微服务到 Kubernetes 之前，我们首先需要准备好以下工作环境和所需工具：\n一个运行正常的 Kubernetes 集群，可以是本地的 minikube 集群或者云上的托管 Kubernetes 服务。 已经构建好的 Spring Boot 应用程序的 Docker 镜像，可以通过 Dockerfile 构建，或者使用 Maven 插件和 Docker 插件直接构建。 Kubernetes 部署和服务资源的 YAML 配置文件，用于定义应用程序的部署、服务和健康检查配置。 # 4. 在 Kubernetes 中部署 Spring Boot 微服务 在准备工作完成之后，我们就可以开始在 Kubernetes 中部署 Spring Boot 微服务了。首先，我们需要创建一个 Kubernetes 部署资源，用来描述应用程序的容器镜像、副本数等信息。接下来，我们再创建一个 Kubernetes 服务资源，用来暴露应用程序的网络端口，以便其他服务可以访问到该应用程序。让我们一起来看看具体的操作步骤：\n创建 Kubernetes 部署资源： 在 Kubernetes 中，部署资源用于定义应用程序的部署策略和运行配置。我们可以通过一个 YAML 配置文件来创建一个部署资源，示例配置文件如下所示： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 apiVersion: apps/v1 kind: Deployment metadata: name: my-springboot-app spec: replicas: 3 selector: matchLabels: app: my-springboot-app template: metadata: labels: app: my-springboot-app spec: containers: - name: my-springboot-app image: your-docker-registry/my-springboot-app:latest ports: - containerPort: 8080 在这个示例中，我们定义了一个名为 my-springboot-app 的 Deployment 资源，指定了要运行的容器镜像和副本数，并暴露了容器的 8080 端口。\n创建 Kubernetes 服务资源： 在 Kubernetes 中，服务资源用于定义应用程序的网络访问方式和负载均衡策略。我们同样可以通过一个 YAML 配置文件来创建一个服务资源，示例配置文件如下所示： 1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: v1 kind: Service metadata: name: my-springboot-app-service spec: selector: app: my-springboot-app ports: - protocol: TCP port: 80 targetPort: 8080 type: LoadBalancer 在这个示例中，我们定义了一个名为 my-springboot-app-service 的 Service 资源，通过 selector 字段指定了要负载均衡的 Deployment，并将容器的 8080 端口映射到了服务的 80 端口。\n通过上述步骤，我们就可以成功地在 Kubernetes 中部署了一个运行 Spring Boot 微服务的容器应用程序。接下来，我们将重点关注如何配置和实施健康检查，以确保应用程序的稳定性和可靠性。\n# 5. 配置健康检查 在 Kubernetes 中，健康检查通过 liveness 探针和 readiness 探针来实现。liveness 探针用于检查应用程序是否处于运行状态，而 readiness 探针用于检查应用程序是否已准备好接收流量。下面我们将分别介绍如何在 Spring Boot 应用程序中实现这两种探针，并在 Kubernetes 中进行配置。\n实现 liveness 探针： 在 Spring Boot 应用程序中实现 liveness 探针非常简单，我们只需创建一个端点接口，用于检查应用程序的运行状态即可。例如，我们可以创建一个 /actuator/health 的端点，用于返回应用程序的健康状态。在 Spring Boot 应用程序中，我们可以通过 Spring Boot Actuator 模块来实现这一功能。在 application.properties 配置文件中添加以下配置： 1 2 3 management.endpoint.health.enabled=true management.endpoint.health.probes.enabled=true management.endpoints.web.exposure.include=health 然后，我们就可以访问 /actuator/health 端点来检查应用程序的运行状态了。\n实现 readiness 探针： 与 liveness 探针类似，实现 readiness 探针也很简单。我们可以创建一个类似的端点接口，用于检查应用程序是否已准备好接收流量。例如，我们可以创建一个 /actuator/readiness 的端点，用于返回应用程序的就绪状态。同样地，我们可以通过 Spring Boot Actuator 模块来实现这一功能，在 application.properties 配置文件中添加以下配置： 1 2 3 management.endpoint.health.enabled=true management.endpoint.health.probes.enabled=true management.endpoint.health.probes.include=readiness 然后，我们就可以访问 /actuator/readiness 端点来检查应用程序的就绪状态了。\n在 Kubernetes 中配置健康检查： 在 Kubernetes 的部署配置文件中，我们可以通过 livenessProbe 和 readinessProbe 字段来定义容器的健康检查。例如，我们可以使用以下配置来定义一个 liveness 探针： 1 2 3 4 5 6 livenessProbe: httpGet: path: /actuator/health port: 8080 initialDelaySeconds: 30 periodSeconds: 10 这个配置将会在容器启动后等待 30 秒后开始进行 liveness 探测，每隔 10 秒进行一次探测，检查 /actuator/health 端点的返回状态。\n类似地，我们也可以使用类似的配置来定义一个 readiness 探针。\n通过上述步骤，我们就成功地在 Spring Boot 应用程序中实现了 liveness 探针和 readiness 探针，并在 Kubernetes 中进行了相应的配置。接下来，我们将进行实战演练，验证健康检查的配置是否生效，以及如何使用 kubectl 命令来查看应用程序的健康状态。\n# 6. 验证 在本节中，我们将演示如何使用 kubectl 命令来查看应用程序的健康状态，并验证健康检查的配置是否生效。\n查看 liveness 探针状态： 使用以下命令可以查看应用程序的 liveness 探针状态： 1 kubectl describe pod \u0026lt;pod_name\u0026gt; 该命令将输出包含容器状态和事件的详细信息。在输出结果中，可以找到有关 liveness 探针的相关信息，例如探针的执行结果和最后一次执行的时间戳。\n验证 readiness 探针状态： 使用以下命令可以验证应用程序的 readiness 探针状态： 1 kubectl get pods 该命令将列出所有运行中的 Pod，并显示它们的状态。通过观察 READY 列中的值，可以了解到每个 Pod 是否已准备好接收流量。\n通过上述命令，我们可以轻松地验证健康检查的配置是否生效，并了解应用程序的健康状态。如果出现健康检查失败或异常的情况，我们还可以使用 kubectl 命令来进行故障排除和调试，以找出问题的根源并及时处理。\n# 7. 总结 通过本文的实战指南，我们深入探讨了在 Kubernetes 环境中部署 Spring Boot 微服务并实施健康检查的方法和步骤。我们首先介绍了健康检查的概念和重要性，然后详细讲解了如何在 Spring Boot 应用程序中实现 liveness 探针和 readiness 探针，并在 Kubernetes 中进行配置。最后，我们进行了实战演练，验证了健康检查的配置是否生效，并了解了如何使用 kubectl 命令来查看应用程序的健康状态和进行故障排除。\n通过正确地配置和实施健康检查，我们可以有效地监控和管理应用程序的状态，及时发现并处理潜在的故障情况，从而确保整个系统的正常运行。希望本文对您理解和掌握云原生健康检查的实践技巧有所帮助，也欢迎您在实际应用中进行进一步的尝试和探索。\n# 参考资料 https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#container-probes https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator.endpoints.kubernetes-probes https://docs.spring.io/spring-boot/docs/current/reference/html/deployment.html#deployment.cloud.kubernetes.container-lifecycle https://docs.spring.io/spring-boot/docs/current/reference/html/web.html#web.graceful-shutdown ","date":"2024-04-20T21:00:00Z","image":"https://xiuwei.github.io/p/kubernetes-springboot-health-check/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_1001946_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/kubernetes-springboot-health-check/","title":"实战指南：在 Kubernetes 上部署 Spring Boot 微服务并实施健康检查"},{"content":" # AMQP 0-9-1 和 AMQP 模型高阶概述 # AMQP 0-9-1 是什么? AMQP（高级消息队列协议）是一个网络协议。它支持符合要求的客户端应用（application）和消息中间件代理（messaging middleware broker）之间进行通信。\n# 消息代理（Brokers）和他们所扮演的角色 消息代理（Messaging brokers）从发布者（publishers）亦称生产者（producers）那儿接收消息，并根据既定的路由规则把接收到的消息发送给处理消息的消费者（consumers）。\n由于AMQP是一个网络协议，所以这个过程中的发布者，消费者，消息代理 可以存在于不同的设备上。\n# AMQP 0-9-1 模型简介 AMQP 0-9-1的工作过程如下图：消息（message）被发布者（publisher）发送给交换机（exchange），交换机常常被比喻成邮局或者邮箱。然后交换机将收到的消息根据路由规则分发给绑定的队列（queue）。最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。\n发布者（publisher）发布消息时可以给消息指定各种消息属性（message meta-data）。有些属性有可能会被消息代理（brokers）使用，然而其他的属性则是完全不透明的，它们只能被接收消息的应用所使用。\n从安全角度考虑，网络是不可靠的，接收消息的应用也有可能在处理消息的时候失败。基于此原因，AMQP模块包含了一个消息确认（message acknowledgements）的概念：当一个消息从队列中投递给消费者后（consumer），消费者会通知一下消息代理（broker），这个可以是自动的也可以由处理消息的应用的开发者执行。当“消息确认”被启用的时候，消息代理不会完全将消息从队列中删除，直到它收到来自消费者的确认回执（acknowledgement）。\n在某些情况下，例如当一个消息无法被成功路由时，消息或许会被返回给发布者并被丢弃。或者，如果消息代理执行了延期操作，消息会被放入一个所谓的死信队列中。此时，消息发布者可以选择某些参数来处理这些特殊情况。\n队列，交换机和绑定统称为AMQP实体（AMQP entities）。\n# AMQP 0-9-1 是一个可编程的协议 AMQP 0-9-1是一个可编程协议，某种意义上说AMQP的实体和路由规则是由应用本身定义的，而不是由消息代理定义。包括像声明队列和交换机，定义他们之间的绑定，订阅队列等等关于协议本身的操作。\n这虽然能让开发人员自由发挥，但也需要他们注意潜在的定义冲突。当然这在实践中很少会发生，如果发生，会以配置错误（misconfiguration）的形式表现出来。\n应用程序（Applications）声明AMQP实体，定义需要的路由方案，或者删除不再需要的AMQP实体。\n# 交换机和交换机类型 交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的。AMQP 0-9-1的代理提供了四种交换机。\nExchange type Default pre-declared names Direct exchange (Empty string) and amq.direct Fanout exchange amq.fanout Topic exchange amq.topic Headers exchange amq.match (and amq.headers in RabbitMQ) 除交换机类型外，在声明交换机时还可以附带许多其他的属性，其中最重要的几个分别是：\nName Durability （消息代理重启后，交换机是否还存在） Auto-delete （当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它） Arguments（依赖代理本身） 交换机可以有两个状态：持久（durable）、暂存（transient）。持久化的交换机会在消息代理（broker）重启后依旧存在，而暂存的交换机则不会（它们需要在代理再次上线后重新被声明）。然而并不是所有的应用场景都需要持久化的交换机。\n# 默认交换机（Default Exchange） 默认交换机（default exchange）实际上是一个由消息代理预先声明好的没有名字（名字为空字符串）的直连交换机（direct exchange）。它有一个特殊的属性使得它对于简单应用特别有用处：那就是每个新建队列（queue）都会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。\n举个栗子：当你声明了一个名为\u0026quot;search-indexing-online\u0026quot;的队列，AMQP代理会自动将其绑定到默认交换机上，绑定（binding）的路由键名称也是为\u0026quot;search-indexing-online\u0026quot;。因此，当携带着名为\u0026quot;search-indexing-online\u0026quot;的路由键的消息被发送到默认交换机的时候，此消息会被默认交换机路由至名为\u0026quot;search-indexing-online\u0026quot;的队列中。换句话说，默认交换机看起来貌似能够直接将消息投递给队列，尽管技术上并没有做相关的操作。\n# 直连交换机（Direct Exchange） 直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的。直连交换机用来处理消息的单播路由（unicast routing）（尽管它也可以处理多播路由）。\n下边介绍它是如何工作的：\n将一个队列绑定到某个交换机上，同时赋予该绑定一个路由键（routing key）K 当一个携带着路由键为 R 的消息被发送给直连交换机时，交换机会把它路由给绑定值同样为R的队列，即K = R 如果多个队列绑定到具有相同路由键 K 的直接交换机，则交换机会将消息路由到 K = R 的所有队列 # 扇型交换机（Fanout Exchange） 扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。扇型用来交换机处理消息的广播路由（broadcast routing）。\n因为扇型交换机投递消息的拷贝到所有绑定到它的队列，所以他的应用案例都极其相似：\n大规模多用户在线（MMO）游戏可以使用它来处理排行榜更新等全局事件 体育新闻网站可以用它来近乎实时地将比分更新分发给移动客户端 分发系统使用它来广播各种状态和配置更新 在群聊的时候，它被用来分发消息给参与群聊的用户。（AMQP没有内置presence的概念，因此XMPP可能会是个更好的选择） # 主题交换机（Topic Exchange） 主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。主题交换机经常用来实现各种分发/订阅模式及其变种。主题交换机通常用来实现消息的多播路由（multicast routing）。\n主题交换机拥有非常广泛的用户案例。无论何时，当一个问题涉及到那些想要有针对性的选择需要接收消息的 多消费者/多应用（multiple consumers/applications） 的时候，主题交换机都可以被列入考虑范围。\n使用案例：\n分发有关于特定地理位置的数据，例如销售点 由多个工作者（workers）完成的后台任务，每个工作者负责处理某些特定的任务 股票价格更新（以及其他类型的金融数据更新） 涉及到分类或者标签的新闻更新（例如，针对特定的运动项目或者队伍） 云端的不同种类服务的协调 分布式架构/基于系统的软件封装，其中每个构建者仅能处理一个特定的架构或者系统。 # 头交换机（Headers Exchange） 有时消息的路由操作会涉及到多个属性，此时使用消息头就比用路由键更容易表达，头交换机（headers exchange）就是为此而生的。头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。\n我们可以绑定一个队列到头交换机上，并给他们之间的绑定使用多个用于匹配的头（header）。这个案例中，消息代理得从应用开发者那儿取到更多一段信息，换句话说，它需要考虑某条消息（message）是需要部分匹配还是全部匹配。上边说的“更多一段消息”就是\u0026quot;x-match\u0026quot;参数。当\u0026quot;x-match\u0026quot;设置为“any”时，消息头的任意一个值被匹配就可以满足条件，而当\u0026quot;x-match\u0026quot;设置为“all”的时候，就需要消息头的所有值都匹配成功。\n头交换机可以视为直连交换机的另一种表现形式。头交换机能够像直连交换机一样工作，不同之处在于头交换机的路由规则是建立在头属性值之上，而不是路由键。路由键必须是一个字符串，而头属性值则没有这个约束，它们甚至可以是整数或者哈希值（字典）等。\n# 队列（Queues） AMQP中的队列（queue）跟其他消息队列或任务队列中的队列是很相似的：它们存储着即将被应用消费掉的消息。队列跟交换机共享某些属性，但是队列也有一些另外的属性。\nName Durable（消息代理重启后，队列依旧存在） Exclusive（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） Auto-delete（当最后一个消费者退订后即被删除） Arguments（一些消息代理用他来完成类似与TTL的某些额外功能） 队列在声明（declare）后才能被使用。如果一个队列尚不存在，声明一个队列会创建它。如果声明的队列已经存在，并且属性完全相同，那么此次声明不会对原有队列产生任何影响。如果声明中的属性与已存在队列的属性有差异，那么一个错误代码为406的通道级异常就会被抛出。\n# 队列名称 队列的名字可以由应用（application）来取，也可以让消息代理（broker）直接生成一个。队列的名字可以是最多255字节的一个utf-8字符串。若希望AMQP消息代理生成队列名，需要给队列的name参数赋值一个空字符串：在同一个通道（channel）的后续的方法（method）中，我们可以使用空字符串来表示之前生成的队列名称。之所以之后的方法可以获取正确的队列名是因为通道可以默默地记住消息代理最后一次生成的队列名称。\n以\u0026quot;amq.\u0026ldquo;开始的队列名称被预留做消息代理内部使用。如果试图在队列声明时打破这一规则的话，一个通道级的403 (ACCESS_REFUSED)错误会被抛出。\n# 队列持久化（Queue Durability） 持久化队列（Durable queues）会被存储在磁盘上，当消息代理（broker）重启的时候，它依旧存在。没有被持久化的队列称作暂存队列（Transient queues）。并不是所有的场景和案例都需要将队列持久化。\n持久化的队列并不会使得路由到它的消息也具有持久性。倘若消息代理挂掉了，重新启动，那么在重启的过程中持久化队列会被重新声明，无论怎样，只有经过持久化的消息才能被重新恢复。\n# 绑定（Bindings） 绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则。如果要指示交换机“E”将消息路由给队列“Q”，那么“Q”就需要与“E”进行绑定。绑定操作需要定义一个可选的路由键（routing key）属性给某些类型的交换机。路由键的意义在于从发送给交换机的众多消息中选择出某些消息，将其路由给绑定的队列。\n打个比方：\n队列（queue）是我们想要去的位于纽约的目的地 交换机（exchange）是JFK机场 绑定（binding）就是JFK机场到目的地的路线。能够到达目的地的路线可以是一条或者多条 拥有了交换机这个中间层，很多由发布者直接到队列难以实现的路由方案能够得以实现，并且避免了应用开发者的许多重复劳动。\n如果AMQP的消息无法路由到队列（例如，发送到的交换机没有绑定队列），消息会被就地销毁或者返还给发布者。如何处理取决于发布者设置的消息属性。\n# 消费者（Consumers） 消息如果只是存储在队列里是没有任何用处的。被应用消费掉，消息的价值才能够体现。在AMQP 0-9-1 模型中，有两种途径可以达到此目的：\n将消息投递给应用 (\u0026ldquo;push API\u0026rdquo;) 应用根据需要主动获取消息 (\u0026ldquo;pull API\u0026rdquo;) 使用push API，应用（application）需要明确表示出它在某个特定队列里所感兴趣的，想要消费的消息。如是，我们可以说应用注册了一个消费者，或者说订阅了一个队列。一个队列可以注册多个消费者，也可以注册一个独享的消费者（当独享消费者存在时，其他消费者即被排除在外）。\n每个消费者（订阅者）都有一个叫做消费者标签的标识符。它可以被用来退订消息。消费者标签实际上是一个字符串。\n# 消息确认（Message Acknowledgements） 消费者应用（Consumer applications） - 用来接受和处理消息的应用 - 在处理消息的时候偶尔会失败或者有时会直接崩溃掉。而且网络原因也有可能引起各种问题。这就给我们出了个难题，AMQP代理在什么时候删除消息才是正确的？AMQP 0-9-1 规范给我们两种建议：\n当消息代理（broker）将消息发送给应用后立即删除。（使用AMQP方法：basic.deliver或basic.get-ok） 待应用（application）发送一个确认回执（acknowledgement）后再删除消息。（使用AMQP方法：basic.ack） 前者被称作自动确认模式（automatic acknowledgement model），后者被称作显式确认模式（explicit acknowledgement model）。在显式模式下，由消费者应用来选择什么时候发送确认回执（acknowledgement）。应用可以在收到消息后立即发送，或将未处理的消息存储后发送，或等到消息被处理完毕后再发送确认回执（例如，成功获取一个网页内容并将其存储之后）。\n如果一个消费者在尚未发送确认回执的情况下挂掉了，那AMQP代理会将消息重新投递给另一个消费者。如果当时没有可用的消费者了，消息代理会死等下一个注册到此队列的消费者，然后再次尝试投递。\n# 拒绝消息（Rejecting Messages） 当一个消费者接收到某条消息后，处理过程有可能成功，有可能失败。应用可以向消息代理表明，本条消息由于“拒绝消息（Rejecting Messages）”的原因处理失败了（或者未能在此时完成）。当拒绝某条消息时，应用可以告诉消息代理如何处理这条消息——销毁它或者重新放入队列。当此队列只有一个消费者时，请确认不要由于拒绝消息并且选择了重新放入队列的行为而引起消息在同一个消费者身上无限循环的情况发生。\n# Negative Acknowledgements 在AMQP中，basic.reject方法用来执行拒绝消息的操作。但basic.reject有个限制：你不能使用它决绝多个带有确认回执（acknowledgements）的消息。但是如果你使用的是RabbitMQ，那么你可以使用被称作negative acknowledgements（也叫nacks）的AMQP 0-9-1扩展来解决这个问题。更多的信息请参考帮助页面\n# 预取消息（Prefetching Messages） 在多个消费者共享一个队列的案例中，明确指定在收到下一个确认回执前每个消费者一次可以接受多少条消息是非常有用的。这可以在试图批量发布消息的时候起到简单的负载均衡和提高消息吞吐量的作用。For example, if a producing application sends messages every minute because of the nature of the work it is doing.（？？？例如，如果生产应用每分钟才发送一条消息，这说明处理工作尚在运行。）\n注意，RabbitMQ只支持通道级的预取计数，而不是连接级的或者基于大小的预取。\n# 消息属性和有效载荷（Message Attributes and Payload） AMQP模型中的消息（Message）对象是带有属性（Attributes）的。有些属性及其常见，以至于AMQP 0-9-1 明确的定义了它们，并且应用开发者们无需费心思思考这些属性名字所代表的具体含义。例如：\nContent type（内容类型） Content encoding（内容编码） Routing key（路由键） Delivery mode (persistent or not) 投递模式（持久化 或 非持久化） Message priority（消息优先权） Message publishing timestamp（消息发布的时间戳） Expiration period（消息有效期） Publisher application id（发布应用的ID） 有些属性是被AMQP代理所使用的，但是大多数是开放给接收它们的应用解释器用的。有些属性是可选的也被称作消息头（headers）。他们跟HTTP协议的X-Headers很相似。消息属性需要在消息被发布的时候定义。\nAMQP的消息除属性外，也含有一个有效载荷 - Payload（消息实际携带的数据），它被AMQP代理当作不透明的字节数组来对待。消息代理不会检查或者修改有效载荷。消息可以只包含属性而不携带有效载荷。它通常会使用类似JSON这种序列化的格式数据，为了节省，协议缓冲器和MessagePack将结构化数据序列化，以便以消息的有效载荷的形式发布。AMQP及其同行者们通常使用\u0026quot;content-type\u0026rdquo; 和 \u0026ldquo;content-encoding\u0026rdquo; 这两个字段来与消息沟通进行有效载荷的辨识工作，但这仅仅是基于约定而已。\n消息能够以持久化的方式发布，AMQP代理会将此消息存储在磁盘上。如果服务器重启，系统会确认收到的持久化消息未丢失。简单地将消息发送给一个持久化的交换机或者路由给一个持久化的队列，并不会使得此消息具有持久化性质：它完全取决与消息本身的持久模式（persistence mode）。将消息以持久化方式发布时，会对性能造成一定的影响（就像数据库操作一样，健壮性的存在必定造成一些性能牺牲）。\n# AMQP 0-9-1 方法 AMQP 0-9-1由许多方法（methods）构成。方法即是操作，这跟面向对象编程中的方法没半毛钱关系。AMQP的方法被分组在类（class）中。这里的类仅仅是对AMQP方法的逻辑分组而已。在 AMQP 0-9-1参考 中有对AMQP方法的详细介绍。\n让我们来看看交换机类，有一组方法被关联到了交换机的操作上。这些方法如下所示：\nexchange.declare exchange.declare-ok exchange.delete exchange.delete-ok （请注意，RabbitMQ网站参考中包含了特用于RabbitMQ的交换机类的扩展，这里我们不对其进行讨论）\n以上的操作来自逻辑上的配对：exchange.declare 和 exchange.declare-ok，exchange.delete 和 exchange.delete-ok. 这些操作分为“请求 - requests”（由客户端发送）和“响应 - responses”（由代理发送，用来回应之前提到的“请求”操作）。\n如下的例子：客户端要求消息代理使用exchange.declare方法声明一个新的交换机： 如上图所示，exchange.declare方法携带了好几个参数。这些参数可以允许客户端指定交换机名称、类型、是否持久化等等。\n操作成功后，消息代理使用exchange.declare-ok方法进行回应： exchange.declare-ok方法除了通道号之外没有携带任何其他参数（通道-channel 会在本指南稍后章节进行介绍）。\nAMQP队列类的配对方法 - queue.declare方法 和 queue.declare-ok有着与其他配对方法非常相似的一系列事件： 不是所有的AMQP方法都有与其配对的“另一半”。许多（basic.publish是最被广泛使用的）都没有相对应的“响应”方法，另外一些（如basic.get）有着一种以上与之对应的“响应”方法。\n# 连接（Connections） AMQP连接通常是长连接。AMQP是一个使用TCP提供可靠投递的应用层协议。AMQP使用认证机制并且提供TLS（SSL）保护。当一个应用不再需要连接到AMQP代理的时候，需要优雅的释放掉AMQP连接，而不是直接将TCP连接关闭。\n# 通道（Channels） 有些应用需要与AMQP代理建立多个连接。无论怎样，同时开启多个TCP连接都是不合适的，因为这样做会消耗掉过多的系统资源并且使得防火墙的配置更加困难。AMQP 0-9-1提供了通道（channels）来处理多连接，可以把通道理解成共享一个TCP连接的多个轻量化连接。\n在涉及多线程/进程的应用中，为每个线程/进程开启一个通道（channel）是很常见的，并且这些通道不能被线程/进程共享。\n一个特定通道上的通讯与其他通道上的通讯是完全隔离的，因此每个AMQP方法都需要携带一个通道号，这样客户端就可以指定此方法是为哪个通道准备的。\n# 虚拟主机（Virtual Hosts） 为了在一个单独的代理上实现多个隔离的环境（用户、用户组、交换机、队列 等），AMQP提供了一个虚拟主机（virtual hosts - vhosts）的概念。这跟Web servers虚拟主机概念非常相似，这为AMQP实体提供了完全隔离的环境。当连接被建立的时候，AMQP客户端来指定使用哪个虚拟主机。\n# AMQP是可扩展的 AMQP 0-9-1 拥有多个扩展点：\n定制化交换机类型 可以让开发者们实现一些开箱即用的交换机类型尚未很好覆盖的路由方案。例如 geodata-based routing。 交换机和队列的声明中可以包含一些消息代理能够用到的额外属性。例如RabbitMQ中的per-queue message TTL即是使用该方式实现。 特定消息代理的协议扩展。例如RabbitMQ所实现的扩展。 新的 AMQP 0-9-1 方法类可被引入。 消息代理可以被其他的插件扩展，例如RabbitMQ的管理前端 和 已经被插件化的HTTP API。 这些特性使得AMQP 0-9-1模型更加灵活，并且能够适用于解决更加宽泛的问题。\n# AMQP 0-9-1 客户端生态系统 AMQP 0-9-1 拥有众多的适用于各种流行语言和框架的客户端。其中一部分严格遵循AMQP规范，提供AMQP方法的实现。另一部分提供了额外的技术，方便使用的方法和抽象。有些客户端是异步的（非阻塞的），有些是同步的（阻塞的），有些将这两者同时实现。有些客户端支持“供应商的特定扩展”（例如RabbitMQ的特定扩展）。\n因为AMQP的主要目标之一就是实现交互性，所以对于开发者来讲，了解协议的操作方法而不是只停留在弄懂特定客户端的库就显得十分重要。这样一来，开发者使用不同类型的库与协议进行沟通时就会容易的多。\n# 参考资料 https://www.rabbitmq.com/tutorials/amqp-concepts#amqp-methods ","date":"2024-04-12T21:00:00Z","image":"https://xiuwei.github.io/p/amqp_0-9-1_model_explained/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_2702306_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/amqp_0-9-1_model_explained/","title":"解析 AMQP 0-9-1 模型：构建可靠的消息传递系统"},{"content":" # 前言 如果在阅读日志时，你遇到以下问题，说明你的日志打印需要规范起来：\n过多或冗余的日志，干扰排障：有时候，系统可能会记录过多的日志信息，包括一些无关紧要的或冗余的信息。这会导致日志文件过大，不易于查找和分析关键的日志记录； 缺乏一致性和标准化： 在多个模块或组件中，日志格式和结构可能不一致，导致日志的解析和分析困难。缺乏统一的标准化规范，使得日志的可读性和可维护性下降； 缺乏上下文信息：打印日志时，只把原始的错误打印出来，没有补充打印上下文信息，例如：请求参数、关键变量值等，导致排障困难，需要重新复现； 同一个错误层层打印：例如在 Go 简洁架构中，同一个错误日志分别在 Use Case 层和 Service 层分别打印，导致在排障时带来冗余日志干扰，还会导致程序性能下降、浪费存储空间等； 根因丢失，无法快速定位故障点：有时候，错误日志在向上传递过程中，如果做了包装，要附带一些信息，最原始的报错日志可能就会丢失，导致很难定位出错误根因。 日志规范是为了提高日志的可读性、可维护性和可搜索性而制定的一系列规则和约定。将日志打印规范化，可以带来以下好处：\n可读性：日志规范可以定义日志的格式、结构和语义，使日志信息更易于理解和解读。统一的日志格式可以让开发人员、运维人员和其他团队成员更容易阅读和理解日志，从而更快地定位和解决问题； 可维护性：日志规范可以定义日志的级别、分类和命名规则，使日志更易于管理和维护。通过规范化的日志级别和分类，可以更好地组织和过滤日志，只关注关键的日志信息，减少冗余和无用的日志记录； 可搜索性：日志规范可以定义日志的关键字、标签和结构，使日志更易于搜索和过滤。通过定义一致的日志结构和关键字，可以使用日志分析工具或搜索引擎来快速搜索和过滤日志，以便查找特定的事件、错误或异常； 故障排查：日志规范可以帮助定位和排查故障。规范的日志格式和结构可以提供更多的上下文信息，包括时间戳、请求参数、异常堆栈等，有助于分析和理解故障现象，加快故障排查的速度和准确性； 性能优化：日志规范可以帮助识别和优化性能问题。通过规范化的日志记录和度量指标，可以更好地监控和分析系统的性能表现，发现潜在的性能瓶颈和优化机会。 可以看到，日志规范是提高日志质量和效用的重要工具。通过制定和遵守日志规范，可以提升团队协作效率，加快故障排查和问题解决的速度，提高系统的可靠性和性能。\n本文就来介绍下日志记录需要遵循的规范。这些日志规范分为以下 2 类：\n必须遵循的：这类规范是所有组件记录日志时都要遵循的规范； 建议遵循的：这些规范是根据需要选择性需要遵循的规范。 # 日志打印规范 # 【强制】必须遵循的规范] 所有日志均使用英文进行记录； 记录日志时，要明确日志级别，选择正确的日志级别； 打印结构化的日志，不要拼接字符串， 采用 KV 模式； 日志均以大写开头，结尾不跟 .（可以接受问号和感叹号，但不推荐），例如：log.Errorw(err, \u0026ldquo;Failed to create lru cache\u0026rdquo;)； 使用过去时，例如：Could not delete B 而不是 Cannot delete B； 日志信息应使用主语进行记录，当有执行主体时使用完整句子 （A could not do B），如果主体是程序本身则省略主语（Could not do B）； 日志要脱敏，禁止输出敏感的信息，例如：密码、密钥、手机号、IP 等信息； 为了方便阅读日志，日志禁止换行； 日志中不要记录无用信息，防止无用日志淹没重要信息； 日志信息要准确全面，努力做到仅凭日志就可以定位问题； Error 日志必须记录完整的上下文信息，例如：完整输入和输出、关键变量的值等； 使用 Warn 级别记录用户输入参数错误导致的程序错误。因为我们 Error 和 Warn 级别的日志告警策略不同，在 Warn 级别打印，可以避免频繁告警； 确保日志打印语句不 Panic，例如：klog.V(4).Infof(\u0026ldquo;Connection error: %s %s: %v\u0026rdquo;, t.Op, t.URL, t.Err)，如果 t 是 nil 就会导致日志调用时发生 panic，会大大加大排障难度； 日志信息禁用字符串拼接，而要使用占位符。使用占位符，格式更清晰，性能更优。例如：klog.V(4).Infof(\u0026ldquo;Get login token: %s\u0026rdquo;, rp.Token)； 所有 Operator、Controller、Kube APIServer Style 的组件为了跟 K8S 生态保持兼容，统一使用 k8s.io/klog/v2open in new window 包。所有非 Operator、Controller、Kube APIServer Style 的组件统一使用 github.com/superproj/onex/pkg/logopen in new window 包； 当时用 k8s.io/klog/v2open in new window 记录日志时，需要遵循以下规范： 要使用结构化的日志记录方式：klog.InfoS， klog.ErrorS。Example: klog.InfoS(\u0026ldquo;Received HTTP request\u0026rdquo;, \u0026ldquo;method\u0026rdquo;, \u0026ldquo;GET\u0026rdquo;, \u0026ldquo;URL\u0026rdquo;, \u0026ldquo;/metrics\u0026rdquo;, \u0026ldquo;latency\u0026rdquo;, time.Second); 日志级别： Error 级别日志使用：klog.ErrorS； Warning 级别日志使用：klog.V(1).InfoS； Info 级别日志使用：klog.V(2).InfoS； Debug 级别日志使用：klog.V(4).InfoS； Trace 级别日志使用：klog.V(5).InfoS。 日志键值对，值规范如下： 优先使用klog.KObj 或 klog.KObjSlice来记录 Kubernetes 对象； 当日志记录对象不是一个标准的 Kubernetes 资源对象时，使用klog.KRef； 当日志记录对象是单个 Kubernetes 资源对象时（例如：*v1.Pod），使用klog.KObj； 当日志记录对象是 Kubernetes 资源对象数组时（例如[]*v1.Pod），使用klog.KObjSlice。 优先传递结构化的对象，而非object.String()； 当期望将[]byte类型的对象作为string类型记录时，需要明确使用string()进行转换； 如果使用 github.com/superproj/onex/pkg/log日志包：open in new window 要使用结构化的日志记录方式：log.C(ctx).Errorw()、log.C(ctx).Infow()等； 如果日志能获取到 context.Context 变量，需要使用 log.C() 函数打印，例如：log.C(ctx).Warnw(\u0026ldquo;please enable redis, otherwise the idempotent is invalid\u0026rdquo;)。使用 log.C(ctx) 可以输出必要的 KV，例如：trace.idopen in new window、user.idopen in new window 等。 不要使用 Fatal 级别的日志，因为 Fatal 级别的日志会调用 os.Exit(255) 导致日志退出。如果确实需要退出，请先打印 Error 级别的日志，在调用 os.Exit(255) 显示退出程序； 不要使用 Panic 级别的日志，这会导致程序 Panic，造成服务不稳定。如果程序需要 Panic，可以通过返回 error，并处理改 error 来达到相同的目的； 线上日志至少要保留 15 天，因为异常日志具有以 周 为频次发生的特点，保留 15 天，可以帮助你在排障时，有日志可以查询； 在 Debug、排障过程中，持续不断优化日志输出，定期对代码日志进行 review。如果定位问题时间过长则说明日志需要优化。 提示：\n任何日志事件都可以简单归为错误日志和非错误日志，所以在使用klog记录日志时，只使用了klog.ErrorS 和klog.InfoS； 在日志消息中，关于开头字母大小写的惯例因开发团队而异。一些团队更喜欢使用大写字母开头，这有助于强调重要性，以及使日志更易读，尤其是在较长的日志行中。而其他团队更倾向于使用小写字母，因为这样的日志看起来更加紧凑和一致； 无用日志常见情况： 能够放在一条日志中的东西放在多条日志中输出； 预期会发生且能够正常处理的异常，打印一堆无用的堆栈； 为了开发调试方便而加入的“临时”日志； 日志过少的情况有： 请求出错时不能通过日志直接定位问题，需要添加临时日志并重新请求才能定位问题； 无法确定服务中的后台任务是否按照期望执行； 无法确定服务的内存数据结构的状态； 无法确定服务的异常处理逻辑（如重试）是否正常执行； 无法确定服务启动时配置是否正确加载。 \u0026hellip; # 【建议】建议遵循的规范 请遵循日志打印基本原则：日志信息要简明扼要、易理解、易搜索，并包含排障所需的上下文 失败日志建议格式为 Failed to \u0026lt;动词\u0026gt; + \u0026lt;一些事\u0026gt;，例如：log.Errorw(err, \u0026ldquo;Failed to initialize casbin adapter\u0026rdquo;)； 成功日志建议格式为 \u0026lt;动词\u0026gt; + \u0026lt;一些事\u0026gt;，例如：log.Infow(\u0026ldquo;Initialize idempotent success\u0026rdquo;)。 共享库，例如：github.com/superproj/onex/pkg/dbopen in new window 只返回错误，不记录日志。因为共享库可能会用在命令行工具、其他项目中，如果记录日志，势必会造成命令行工具有日志输出，影响使用体验、共享库的日志输出跟其他项目的日志输出格式不一致等问题； 日志包名字统一为 github.com/superproj/onex/pkg/logopen in new window 或 k8s.io/klog/v2，如果同一个文件中有其他同名的日志包，需要将其他日志包重命名，而且重命名的名字要在open in new window中保持一致，例如：kratoslog \u0026ldquo;github.com/go-kratos/kratos/v2/logopen in new window\u0026quot;； Error 日志应该在最原始的报错位置打印，一是避免上层代码缺失部分入参，二是避免漏打； 服务初始化时，成功信息和失败信息都需要打印，影响启动的错误需要 panic，并打印 FATAL 日志； 打印参数类型已知的情况下，建议按照对应类型格式化方式打印参数；不确定类型可采用 %v；结构体打印可使用 %+v，可将变量名和变量值都打印出来，但需要注意结构体包含指针类型变量，那打印的只是地址信息，因此需要单独打印。 # 选择合适的日志级别 不同级别的日志，具有不同的意义，能实现不同的功能，在开发中，我们应该根据目的，在合适的级别记录日志，这里我同样给你一些建议。具体如下表所示：\n日志级别 描述 告警级别 Debug 为了获取足够的信息进行 Debug，通常会在 Debug 级别打印很多日志。例如，可以打印整个 HTTP 请求的请求 Body 或者响应 Body。\nDebug 级别需要打印大量的日志，这会严重拖累程序的性能。并且，Debug 级别的日志，主要是为了能在开发测试阶段更好地 Debug，多是一些不影响现网业务的日志信息。\n所以，对于 Debug 级别的日志，在服务上线时我们一定要禁止掉。否则，就可能会因为大量的日志导致硬盘空间快速用完，从而造成服务宕机，也可能会影响服务的性能和产品体验。\nDebug 这个级别的日志可以随意输出，任何你觉得有助于开发、测试阶段调试的日志，都可以在这个级别打印。 无 Info Info 级别的日志可以记录一些有用的信息，供以后的运营分析，所以 Info 级别的日志不是越多越好，也不是越少越好，应以满足需求为主要目标。一些关键日志，可以在 Info 级别记录，但如果日志量大、输出频度过高，则要考虑在 Debug 级别记录。\n现网的日志级别一般是 Info 级别，为了不使日志文件占满整个磁盘空间，在记录日志时，要注意避免产生过多的 Info 级别的日志。例如，在 for 循环中，就要慎用 Info 级别的日志。 无 Warn 一些警告类的日志可以记录在 Warn 级别，Warn 级别的日志表示遇到了预期之内的错误，并且已经进行了处理，不会影响主要功能。像这些日志，就需要你关注起来。Warn 更多的是业务级别的警告日志。 Lark Error Error 级别的日志告诉我们程序执行出错，这些错误肯定会影响到程序的执行结果，例如请求失败、创建资源失败等。要记录每一个发生错误的日志，避免日后排障过程中这些错误被忽略掉。大部分的错误可以归在 Error 级别 Lark 转电话 Panic Panic 级别的日志在实际开发中很少用，通常只在需要错误堆栈，或者不想因为发生严重错误导致程序退出，而采用 defer 处理错误时使用 Lark + 电话 Fatal Fatal 是最高级别的日志，这个级别的日志说明问题已经相当严重，严重到程序无法继续运行，通常是系统级的错误。在开发中也很少使用，除非我们觉得某个错误发生时，整个程序无法继续运行 Lark + 电话 根据的日志规范 Panic、Fatal 级别的日志不需要打印，如果需要，可以使用Error 级别的日志 + os.Exit() 进行处理。\n通常， 为了能够及时发现问题并排障，在发生错误日志时，要告警通知到相关的研发或运维，上述表格，也针对不同的日志级别，给出了告警级别，供你参考。\n提示：Lark 指代飞书办公软件。\n日志级别选择图： 这里用一张图来总结下，如何选择 Debug、Info、Warn、Error、Panic、Fatal 这几种日志级别。\n# 日志打印时机 在打印日志时，要选择合适的时机进行打印，不能随便打印。\n# 建议打印时机 日志主要是用来定位问题的，所以整体来说，我们要在有需要的地方打印日志。那么具体是哪些地方呢？我给你几个建议。\n打印程序的配置参数：系统在启动过程中通常会首先读启动参数，可以在系统启动后将这些参数输出到日志中，方便确认系统是按照期望的参数启动的； 网络通信部分：发送请求前、收到请求结果均应打印 Info 级别的日志。根据我的研发经验，如果你的程序调用了第三方组件，在排障时，需要提供给第三方组件的研发/运维足够的上下文，帮助复现问题，才会得到他们及时有效的支持，所以这里建议在请求第三方接口时，至少要记录请求包、返回包、URL 等信息。注意，如果请求包和返回包很大，需谨慎打印； 在分支语句处打印日志：在分支语句处打印日志，可以判断出代码走了哪个分支，有助于判断请求的下一跳，继而继续排查问题； 写操作必须打印日志：写操作最可能会引起比较严重的业务故障，写操作打印日志，可以在出问题时找到关键信息； 非预期执行时打印日志：如果程序走到了跟我们预期不一样的分支，需要打印日志。例如：正常情况下，服务的某个状态应该是 Running 的，但真实的状态是 Pending 的，这种异常的状态，很可能会带来问题，后期可能需要定位排障，这时候可以打印相关日志； 后台定期执行的任务：如定期更新缓存的任务，可以记录任务开始时间，任务结束时间，更新了多少条缓存配置等等，这样可以掌握定期执行的任务的状态； 业务流程关键节点：我们经常会面对流程比较复杂的业务流程，在整个流程的关键节点上，可以记录下日志，例如，当进行物品交换时，可以将要交换的物品打印出来； 数据状态变化时：服务端程序的最核心的逻辑就是维护数据状态的变化，因此，在状态有变化的时候，可以记录下日志，例如，订单从创建状态变为已支付状态时，可以记录日志； 在错误产生的最原始位置打印日志：对于嵌套的 Error，可在 Error 产生的最初位置打印 Error 日志，上层如果不需要添加必要的信息，可以直接返回下层的 Error。我给你举个例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/golang/glog\u0026#34; ) func main() { flag.Parse() defer glog.Flush() if err := loadConfig(); err != nil { glog.Error(err) } } func loadConfig() error { return decodeConfig() // 直接返回 } func decodeConfig() error { if err := readConfig(); err != nil { return fmt.Errorf(\u0026#34;could not decode configuration data for user %s: %v\u0026#34;, \u0026#34;colin\u0026#34;, err) // 添加必要的信息，用户名称 } return nil } func readConfig() error { glog.Errorf(\u0026#34;read: end of input.\u0026#34;) return fmt.Errorf(\u0026#34;read: end of input\u0026#34;) } 通过在最初产生错误的位置打印日志，我们可以很方便地追踪到日志的根源，进而在上层追加一些必要的信息。这可以让我们了解到该错误产生的影响，有助于排障。另外，直接返回下层日志，还可以减少重复的日志打印。\n当代码调用第三方包的函数，且第三方包函数出错时，会打印错误信息。比如：\n1 2 3 if err := os.Chdir(\u0026#34;/root\u0026#34;); err != nil { log.Errorf(\u0026#34;change dir failed: %v\u0026#34;, err) } # 不建议打印时机 当然，在记录日志时，也有有一些地方是不需要记录日志的，这些地方建议如下：\n在循环中打印日志要慎重：如果循环次数过多，会导致打印大量的日志，严重拖累代码的性能，建议的办法是在循环中记录要点，在循环外面总结打印出来； QPS 特别高的接口谨慎打印日志：对于 QPS 特别高的接口，要谨慎选择是否打印日志或者少打印日志，否则可能会影响接口的性能和 CPU 的负载。 # 日志级别设置规范 项目刚刚上线可将日志级别设置为 Debug 级别： github.com/superproj/onex/pkg/logopen in new window 设置 level 为 debug； k8s.io/klog/v2open in new window 设置 -v 为 4。 如果项目经过一段时间的运行，达到一种很稳定的状态，为了不影响性能，需要设置日志级别为 Info： github.com/superproj/onex/pkg/logopen in new window 设置 level 为 info； k8s.io/klog/v2open in new window 设置 -v 为 2。 测试/开发环境可以设置日志级别为 Debug 级别： github.com/superproj/onex/pkg/logopen in new window 设置 level 为 debug； k8s.io/klog/v2open in new window 设置 -v 为 4。 # 日志格式设置规范 线上日志为了便于日志采集工具采集，需要设置为 JSON 格式； 开发、测试环境的日志，可以根据需要设置为TEXT 或 JSON 格式。 # 日志打印检查 Kubernetes 提供了 logcheckopen in new window 工具，来检查 Kubernetes 中的日志记录是否符合规范。你也可以安装，并检查，命令如下：\n1 2 3 $ go install sigs.k8s.io/logtools/logcheck@latest $ logcheck -check-contextual ${ONEX_ROOT}/... $ logcheck -check-structured ${ONEX_ROOT}/... ${ONEX_ROOT}为根目录，你可以根据需要修改检查目录。\n提示：logcheck工具建议可以了解下，真正的项目开发中，并不实用，尤其不适合集成在 CI 流程中，作为项目发布的强制规范检查。因为很多代码确实难以，也不需要完全遵循logcheck工具制定的规范。\n# 其他日志规范参考 Kubernetes 日志记录规范：Loggingopen in new window； Structured and Contextual Logging migration instructions ","date":"2024-04-02T19:00:00Z","image":"https://xiuwei.github.io/p/log-specification/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_5422841_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/log-specification/","title":"日志规范"},{"content":" # 前言 Raft 算法是 Multi-Paxos 算法的一种，是一种强一致性算法。核心就是通过日志复制的方式达到整个集群的副本一致。\nRaft 算法的三个核心概念就是 Leader 的选举、日志复制、节点变更。本文也将从这三个方面进行探讨。之后再聊聊 Raft 算法的几个应用场景。\n# 原理 下面，我们就看看 Raft 算法的一些细节和流程。\n# Leader 选举 Raft 算法中实现一致性的方法很简单：一切听领导的。分布式的环境下节点众多，达成一致最简单粗暴的方法不就是听一个节点的么。\n# 角色变换 Raft 算法中的每个节点都在三种角色之间变换着（一个时间点中一个节点只有一种角色）：Leader（领导者）、Candidate（候选者）、Follower（追随者）。\n领导者，整个集群的核心，其他的节点都追随这个领导者来复制日志内容。领导者主要负责客户端的写请求的处理、发送心跳（告诉其他节点我还活着，没有异常，请不要随便发起选举）、整理日志。 候选者，当领导者节点出现异常（比如长时间没有收到领导者的心跳消息），这时候集群中的其他节点就会把自己的节点角色转为候选者，然后拉选票。最终根据选票数量决定是否成为领导者。 追随者，领导者的小迷弟，永远追随着领导者（也有可能变成候选者或者领导者），主要负责从领导者那里复制日志。 在了解选举过程之前，先介绍几个概念：任期编号、随机超时时间\n# 任期编号 所谓的任期编号就是一个数字而已，每个领导者在任期期间都有一个编号，所有的追随者都以这个编号为准。这个任期在整个选举的过程中起到了至关重要的作用：\n当某个节点长时间没收到领导者的消息，会把自己的任期+1，并且变成候选者 如果某个节点发现自己的任期编号比其他节点的小，那么会将自己的任期编号提高到编号大的那个值 如果某个节点发现自己的任期编号比其他节点的大，会丢弃这条消息 # 随机超时时间 追随者有个特点：当长时间收不到领导者的消息就变成候选者然后去拉选票。那么这个长时间指的是多长时间？Raft 算法里的这个长时间是随机的一个时间，每个节点都不同且随机。\n为什么超时时间是随机的呢？如果每个节点超时时间相同，那么有可能同时发起选票，那就有可能选不出最终的领导者，导致算法无法进行。\n# 选举过程 现在描述下 Raft 算法里的选举过程，假设集群里有三个节点：A、B、C\n首先，起始状态下，集群中所有的节点都是追随者，但是 A 节点的超时时间（与领导者断联系的时间）短，所以A节点先别人一步，把自己变成候选者 A 成为候选者后，把任期编号+1，然后投自己一票。接着再发消息给B、C 用来拉选票 B、C 收到来自 A 的拉选票的消息后，检查下自己在 A 的任期编号下是否投票过、检查下这个任期编号是否合适，如果都满足条件，就把票投给- A，然后把自己的任期编号更新为 A 发过来的任期编号。 当 A 收到来自节点其他大多数节点的选票后，A 就会成为领导者。处理客户端的写请求、发心跳消息给追随者（防止追随者选举成为领导者） 选举的过程有几点注意：\n一个任期内，除非这个领导者自己出现网络延迟等异常，否则会一直领导下去 如果追随者收到多个节点的拉选票的消息，采取先到先得的方式 除了以上的精简过程描述，raft 社区还提供了完整共识过程的可视化展示，这里可以通过原理动画展示选举过程。 http://thesecretlivesofdata.com/raft/\n# 日志复制 Raft 算法选举出领导者之后就能对外提供服务了。领导者接受客户端的写请求，然后记录日志、把日志更新给其他节点，最终整个集群达成一致。\n这里的日志跟 MySQL 底层的那些个实现事物的各种 log 在原理和作用上是类似的。Raft 的日志是由日志项组成，每个日志项包含了一些指令信息、任期编号、索引值等内容。领导者的日志项式最全的（当然啦，因为所有人都听领导者的嘛）且索引值是按照一定的顺序排起来的，这样方便让其他节点查漏补缺。\n# 日志复制过程 那来自客户端的写请求是怎么个处理流程呢？大体如下：\n第一步，领导者先处理写请求，创建新的日志项，写到领导者的本地日志中 第二步，领导者发送这条日志项给其他节点 第三步，当领导者收到大多数节点的回复（比如，其他节点说我已经收到新的日志项了），领导者将自己的状态机（可以理解为最终达成一致的那个状态数据库）更新一下，更新成把新的日志项加入后的最新状态。 第四步，领导者返还给客户端：你的写请求已经成功被我方执行，请放心。 第五步，领导者发在后续的心跳中告诉其他节点：你们可以更新自己的状态机为我现在的状态机的状态了。 非常类似两阶段提交方式的分布式事务……只不过做了点优化\n# 一致性的保障 上面的流程是正常的情况，如果发生非正常的情况，Raft 怎么保证其一致性？其实也挺简单粗暴：强制让追随者的日志项都与领导者一致，并且领导者的日志项永远不会被覆盖或者删除。具体怎么强制让追随者与领导者一致的呢？也很简单：发消息。\n领导者有了最新的日志项，不是要发消息给追随者吗？这条消息里包含了领导者的前一条日志项的一些信息。 追随者收到消息后，检查下这条消息中的前一条日志项的信息是否与自己最新的日志项一致，如果一致，就追加这条最新的日志项到末尾。如果发现不一致，发送失败的消息给领导者。 领导者收到来自追随者失败的消息后，将前一条日志项打包成消息，这条消息包含了前前条日志项的信息。 追随者再次检查消息，跟第二步的检查机制一样，循环往复，直到找到与领导者相同的那条日志项为止。 总结下就是：领导者不停的通过消息与追随者确认两者之间最后一次一致的日志项在哪里，找到这条相同的日志项后，追随者直接强制把与领导者不同的日志项覆盖成领导者的日志项。当然，如果追随者落后的较多，这么一步步的往回走是很低效的，这种情况下领导者可以阶段性发送 snapshots，一次性把落后的节点的日志迅速的追回到某个 snapshots。\n# 节点变更 这里我们继续探讨 Raft 算法中如何保持节点变更后领导者的一致性。领导者网络异常等可以从其他追随者重新选举来保持集群稳定。那如果集群中加入一个或者多个节点后，是否会导致集群不一致呢？如果操作不当，是会的。\n想象这种情况，A、B、C三个节点，A 是领导者，B、C 是追随者，但是 C 是日志项的异常节点。如果这时候突然加了两台机器：D、E，好巧不巧的是 C、D、E 成为了一个新的小集群，然后 C 成为了领导，那就麻烦了。\n如何解决上述的麻烦？也很简单粗暴：加机器的时候一台一台的加就行了。同样的，如果缩减机器也是一台一台的减少。\n# 关于 Raft 的思考 任何算法、技术都在解决问题的同时带来了其他的问题。Raft 也一样，这里笔者总结下其弊端。\nRaft 算法依赖于一个领导者（Leader）节点来协调集群中的其他节点。这意味着领导者节点可能会成为一个性能瓶颈，特别是在处理大量读写请求的情况下。为了解决这个问题，可以采用一些优化策略，如领导者复制和负载均衡。 Raft 算法依赖于集群中大多数节点的响应来达成一致。当集群规模增加时，需要更多的节点来达成一致，这可能导致更高的通信成本和更长的延迟。因此，Raft 算法在大规模分布式系统中的扩展性可能受到限制。 在某些情况下，Raft 算法可能需要几个网络往返才能达到一致性。这会导致一定程度的一致性延迟。对于对实时性要求较高的应用，这种延迟可能会成为一个问题。 # 参考文献 In Search of an Understandable Consensus Algorithm Raft Consensus Algorithm Definition\n","date":"2024-03-25T21:00:00Z","image":"https://xiuwei.github.io/p/exploring-distributed-consistency-algorithm-raft/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_3495804_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/exploring-distributed-consistency-algorithm-raft/","title":"探秘 分布式一致性（共识）算法 ：Raft"},{"content":" # 0. 前言 JetBrains 的产品提供了强大的功能、良好的用户体验、强大的社区支持、跨平台支持以及灵活的许可模式，能够满足开发者在软件开发过程中的各种需求，受到广大开发者的欢迎。\n同时，JetBrains 的产品力尽管非常出色但因为价格昂贵，很多个人开发者都负担不起。如果您又想使用 IntelliJ IDEA Ultimate Edition（专业版），可以参考下面这种方式进行免费激活。\n注意：本文提供方法来自网络，仅供测试使用，请勿用于商业用途，如果喜欢JetBrains的产品，请支持正版！\n# 1. 下载安装 访问 JetBrains IDEA 下载页面 下载合适的版本并完成安装。\n安装完成后，请运行一次软件，进入到 激活/试用 界面后即可关闭软件。\n# 2. 激活 激活工具ja-netfilter最初是zhile大神开发并发布于网络，后续并由热心大佬加工加工，打包成半自动化的激活工具ja-netfilter-all发布，很大程度上降低了使用门槛。\n注意：下面的下载链接如已失效，请访问 https://jetbra.in/s 页面扫描并获取最新的地址\n# 2.1 下载并安装“激活包” 首先，下载激活包，下载后解压到自己预期的目录下（避免误删，此激活包在激活后仍然有用处），内容如下：\n然后进入scripts目录，目录里面是安装脚本\ninstall.sh 用于Linux或者MacOS系统激活IntelliJ IDEA install-all-users.vbs 用于Windows系统针对所有windows用户激活IntelliJ IDEA install-current-user.vbs 用于Windows系统针对当前windows系统用户激活IntelliJ IDEA un开头的文件分别对应上面的卸载脚本。\n根据自己的操作系统情况，选择对应的脚本执行即可完成激活包的安装。\n# 2.2 获取并使用激活码 首先，访问激活码发布站点，选择对应的产品并点击复制激活码到剪切板。\n然后，打开IntelliJ IDEA，点击 \u0026ldquo;Configure\u0026rdquo; -\u0026gt; \u0026ldquo;Manage License\u0026rdquo;。\n选择 \u0026ldquo;Activation Code\u0026rdquo; 并粘贴刚刚复制的激活码。\n点击左下角的的“Activate”按钮即可激活，激活信息如下：\n到此，激活就已经完成了。\n","date":"2024-03-22T21:00:00Z","image":"https://xiuwei.github.io/p/jetbrains-ide-activated/cover_hu833fbab48ae082daa8b5aa933097d7a4_1339223_120x120_fill_box_smart1_3.png","permalink":"https://xiuwei.github.io/p/jetbrains-ide-activated/","title":"IntelliJ IDEA Ultimate 2024 激活（适用全家桶）"},{"content":" # 引言 在分布式系统中，节点之间的信息传播是至关重要的。Gossip 协议作为一种简单而有效的分布式信息传播协议，被广泛应用于各种分布式系统中。本文将带领读者从零开始，通过具体的场景和例子，深入探讨 Gossip 协议的工作原理和应用场景。\n# 基本概念 Gossip，单词本身就是流言、八卦的意思。正如名字一样，Gossip 协议也被称为“流言协议”。它是一种分布式算法，用于在节点之间传递信息。在 Gossip 协议中，每个节点都可以将信息广播给它所知道的其他节点，这些节点又将该信息广播给它们所知道的其他节点，以此类推，直到整个网络都知道了这个信息。这种广播方式可以保证整个网络中的所有节点都能够及时地了解到最新的信息，并确保整个网络的一致性。\n# 背景与意义 关于这个协议的详细论文可查看参考文献一。Gossip 协议通常用于分布式系统中，例如 P2P 网络、分布式数据库、分布式文件系统等。在比特币网络中，也使用了 Gossip 协议来广播新的交易和块。Cassandra 使用的数据复制协议也是 Gossip 算法。还有 Akka、Redis Cluster 都有用到。\n这个算法的最终目的还是一个：达到集群中所有节点的数据一致。只不过这是最终一致性。\n# Gossip 协议的基本原理 这个协议看似简单，实则很复杂。一个一传十、十传百的工作方式真正在分布式的环境下应用起来不是那么容易的。下面我们探讨下其实现细节。\n理解这个协议可以从三个维度：通信方式、协调机制、传播过程。\n# 通信方式 这里所谓的通信方式就是集群中的节点如何建立通信。协议里支持三种：pull、push、push-pull。\n# push 模式 节点 A 将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新A中比自己新的数据\n在推模式中，当一个节点（源节点）需要传播信息时，它会在每个 Gossip 周期（把两个节点数据同步一次定义算作是一个周期）主动将自己的本地数据发送给随机选择的目标节点。目标节点收到信息后，将根据接收到的数据更新自己的本地数据存储。\n推模式的优势在于，信息能够迅速传播到其他节点。但是，它也可能导致节点之间的通信开销较大，因为每个节点在每个周期内都会主动发送信息，即使目标节点可能已经拥有了这些信息。\n# pull 模式 节点 A 仅将数据 key, version 推送给 B ，注意没有value哦， A 推送给 B 时，B 将本地比 A 新的数据（Key, value, version）推送给 A，A 更新本地，这一步相当于A在主动拉取 B 的值。\n在拉模式中，节点不会主动发送信息。相反，它们会在每个 Gossip 周期主动向随机选择的目标节点请求数据。目标节点收到请求后，将自己的本地数据发送给请求节点。请求节点收到数据后，将根据接收到的数据更新自己的本地数据存储。\n拉模式的优势在于，通信开销相对较小，因为节点只在需要时才会请求数据。然而，拉模式可能导致信息传播速度较慢，尤其是在节点数量较多的情况下。\n# push-pull 模式 与 Pull 类似，只是多了一步，A 再将本地比B新的数据推送给 B，B 再更新本地。\n推拉模式结合了推模式和拉模式的优势，既能保证信息的快速传播，又能减小通信开销。在推拉模式中，当一个节点（源节点）需要传播信息时，它会在每个Gossip周期主动将自己的本地数据发送给随机选择的目标节点（推），同时也向目标节点请求数据（拉）。目标节点收到信息后，将根据接收到的数据更新自己的本地数据存储，并将自己的数据发送回源节点。\n推拉模式的优势在于，它可以在保证信息传播速度的同时，降低通信开销。这种模式在大规模分布式系统中尤为突出。\n# 传播策略 了解完通信方式，再来聊聊传播策略，也就是所谓的如何实现最终的一致性。主要有两种：Anti-Entropy(反熵传播)和Rumor-Mongering(谣言传播)。\n# Anti-Entropy(反熵传播) Anti-Entropy 策略通过在节点之间交换数据的摘要来实现信息传播。在每个Gossip 周期内，节点会向随机选择的目标节点发送其本地数据的摘要。目标节点收到摘要后，会比较自己的本地数据和收到的摘要，找出不一致之处。然后，目标节点会向源节点请求缺失或过时的数据。通过这种方式，节点之间的数据最终将达到一致。Anti-Entropy 策略在通信开销和传播速度之间实现了一种平衡，适用于大规模分布式系统。\n这种方式工作量大，一般用于新节点加入时同步更新数据的时候用得到。\n适用场景：执行反熵时，相关的节点都是已知的，而且节点数量不能太多，如果是一个动态变化或节点数比较多的分布式环境（比如在 DevOps 环境中检测节点故障，并动态维护集群节点状态），这时反熵就不适用了。 缺点：消息数量非常庞大，且无限制；通常只用于新加入节点的数据初始化。可以通过引入校验和（Checksum）等机制，降低需要对比的数据量和通讯消息等。 # Rumor-Mongering(谣言传播) Rumor Mongering策略又称为传闻传播策略，它是一种概率论驱动的信息传播方法。在这种策略中，每个节点会在每个Gossip周期内随机选择一个或多个目标节点，并将信息发送给这些目标节点。当目标节点收到信息后，它们也会继续随机选择其他节点并将信息传播出去。这个过程会持续进行，直到信息在整个系统中被广泛传播。Rumor Mongering策略的优点是具有较低的通信开销和较高的可扩展性，但传播速度可能较慢。\n这种方式工作量小，一般用于节点间数据增量的同步。\n适用场景：适合动态变化的分布式系统。 缺点：系统有一定的概率会不一致，通常用于节点间数据增量同步。 # 工作过程 Gossip 协议的工作流程可以简化描述为几个过程：\n种子节点在 Gossip 周期内散播消息 被感染节点随机选择N个邻接节点散播消息 每次散播消息都选择尚未发送过的节点进行散播 这个协议是建立在一定概率的情况下进行的，因为并不是所有节点都时时的能拿到数据，所以这个协议是一种最终一致性算法。\n# 协议的应用于实践 # Apache Cassandra Apache Cassandra是一种高度可扩展的、分布式的NoSQL数据库，它在很大程度上受到了Amazon Dynamo的启发。Cassandra中使用Gossip协议来实现节点间的成员关系管理、故障检测、元数据信息传播以及负载均衡。\n# 成员关系管理和故障检测 在Cassandra中，节点通过Gossip协议来维护成员关系信息。在每个Gossip周期，节点会与随机选择的其他节点交换成员关系信息。这样，节点可以了解其他节点的在线状态和故障情况。此外，Cassandra使用了一种名为Phi Accrual Failure Detector的故障检测机制，它依赖于Gossip协议收集的节点信息来检测节点的可用性。\n# 元数据信息传播 Cassandra中的节点需要维护一定量的元数据，例如分区信息、副本信息和令牌（Token）分配。Gossip协议被用于在节点之间传播这些元数据。在每个Gossip周期内，节点会将自己的元数据发送给随机选择的其他节点。这些节点在收到元数据后，会更新自己的本地数据存储，并将更新后的元数据传播给其他节点。这个过程会持续进行，直到元数据在整个系统中被广泛传播。\n# Redis Cluster Gossip 协议被广泛应用于各种分布式系统中，下面我们将介绍在Redis Cluster的应用场景，并将 Gossip 协议与真实场景结合起来。\nRedis Cluster 是一个分布式的 Redis 解决方案，它允许将数据分布在多个节点上以提高性能和可用性。Gossip 协议用于节点之间的发现和状态同步，每个节点都了解整个集群的拓扑结构以及其他节点的状态信息，以便正确地路由请求和保证数据的一致性。\n想象一下一个大型的工厂，里面有各种各样的生产线。每条生产线都有一个负责人，他们会定期与周围的生产线负责人交流，分享自己所在生产线的状态和工作情况。这样，即使有一部分生产线出现了问题，其他生产线也能够通过周围生产线的信息了解到整个工厂的状态。\nGossip 协议在 Redis Cluster 中的应用主要分为两个方面：\n# 节点发现 当一个新的节点加入到 Redis Cluster 中时，它需要能够自动地发现其他节点，并加入到集群中。这就需要一种机制来实现节点之间的自动发现，而 Gossip 协议恰好提供了这样的功能。每个节点会周期性地与其他节点交换信息，包括自己的地址和状态，从而使新加入的节点能够了解到整个集群的拓扑结构，并与其他节点建立连接。\n# 状态同步 在 Redis Cluster 中，节点之间需要保持数据的一致性，即使某个节点发生了故障或者新的节点加入。为了实现这一点，每个节点都需要了解其他节点的状态信息，如节点的存活状态、负载情况等。通过 Gossip 协议，每个节点可以定期地交换状态信息，从而保持集群中所有节点的状态同步，并及时地做出相应的调整和处理。\n总的来说，Redis Cluster 中的 Gossip 协议通过节点之间的周期性交流信息，实现了节点的发现和状态同步，从而保证了集群的高可用性和一致性。\n# 总结 文中介绍了 Gossip 协议的一些情况。这里简单总结下其优缺点：\n# 优势 快速传播：由于Gossip协议基于随机节点选择进行信息交换，信息可以在很短的时间内传播到大部分节点，实现快速信息传播。 容错性：Gossip协议具有较高的容错性，即使某个节点发生故障或者无法与其他节点通信，信息仍然可以通过其他路径传播。 抗拥塞：随机选择目标节点有助于避免在特定节点上产生通信瓶颈。这使得Gossip协议可以在大规模分布式系统中高效运行。 可扩展性：Gossip协议的设计使得它可以很容易地适应大规模分布式系统，具有较好的可扩展性。 简单易实现：Gossip协议的设计和实现相对简单，易于在各种分布式系统中进行部署。 # 劣势 最终一致性：Gossip协议通常实现的是最终一致性，而不是强一致性。在某些应用场景中，这可能导致数据在短时间内不一致。 带宽消耗：由于Gossip协议的信息交换是基于概率的，可能会导致部分信息多次在节点之间传播，增加了网络带宽消耗。 信息冗余：Gossip协议可能会导致信息冗余，因为每个节点都需要存储关于其他节点的部分信息。 难以保证完全一致性：在某些情况下，由于网络延迟、故障等因素，Gossip协议可能难以保证系统中所有节点的完全一致性。 参数调优：Gossip协议的性能在很大程度上取决于参数设置，例如Gossip周期、目标节点数量等。在实际应用中，需要根据系统的特点和需求进行参数调优，以获得最佳性能。 # 参考文献 Efficient Reconciliation and Flow Control for Anti-Entropy Protocols Wtf is Gossip Protocols? P2P 网络核心技术：Gossip 协议\n","date":"2024-03-15T21:00:00Z","image":"https://xiuwei.github.io/p/exploring-the-gossip-protocol/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_387951_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/exploring-the-gossip-protocol/","title":"探秘 Gossip 协议：从节点交流到信息扩散"},{"content":" # 背景 IPv4 协议（后文简称 IPv4）为互联网的发展与普及做出了重要贡献，但近年来，随着应用程序、数据和 IT 服务的爆炸式增长。当初协议设计过程中用来描述 IP 地址所采用的 32 位二进制数格式的 IPv4 地址已经于 2011 年[1]被申请耗尽，从那时起，全世界都已经处于无新地址可用的局面。\nIPv6 协议（后文简称 IPv6）作为 IPv4 之后被采用的下一代互联网协议，相比 IPv4 协议中采用 32 位来表示 IP 地址，其地址表示位数扩充到了 128 位，地址数量是 IPv4 所能提供的 2 的 96 次方倍。简单看数字可能显得不太直观，换成一句描述 IPv6 地址之多更直观和经典的话：“采用 128 位表示地址的 IPv6 可以为地球上的每一粒沙子都分配一个 IP 地址”！此外，IPv6 协议其不仅可以解决 IPv4 协议中的地址短缺问题，同时也能为互联网提供更高效、更安全的网络通信。IPv6 协议在网络通信中提供了许多新的功能和优势。例如，在数据传输和路由方面，其通过新的设计提高了效率和可靠性，减少了网络拥堵和数据包丢失的情况。此外，在安全领域，其内置对 IPSec 的支持，可以更好地保护网络中的数据传输安全，防止黑客攻击和窃取数据。 作为下一代互联网协议，向 IPv6 迁移是未来的大势所趋。在我国，从 2014 年开始相关机构已经逐步停止向新用户和应用分配 IPv4 地址，开始全面商用 IPv6 协议(计算机网络（第七版）谢希仁)。在政府引导测，近年来，陆续也出台了一系列相关指导文件例如：2017 年国务院发布的《推进互联网协议第六版（IPv6）规模部署行动计划》、2021 年工业与信息化部发布的《IPv6 流量提升三年专项行动计划（2021-2023 年）》、2021 年网信办发布的《关于推动 IPv6 规模部署的指导意见》等不断地在引导企业从 IPv4 协议向 IPv6 协议迁移。 但由于当前互联网中 IPv4 协议的应用规模非常大，对于用户来说，没办法通过规定一个时间日期，从那一刻开始，所有互联网上的设备全部使用 IPv6，这是不现实的。一次性迁移不仅在基础设施层面不可行，对企业用户来说，就算基础设施都能准备完毕，让其将少则上百，多则成千上万的应用实例在一段时间内一次性停机进行协议栈迁移，无论是在风险上，还是成本上，对企业用户来说都是难以接受的！既然无法一步到位，渐进式的 IP 地址迁移成为当前的主流选择。接下来本文将介绍一些主流渐进式的 IP 地址迁移方法。\n# 迁移方案 虽然 IPv6 协议具有许多优势，但是其推广和应用仍然面临许多挑战。IPv6 的普及需要全球范围内的配套基础措施和支持，包括网络设备的更新、人员培训和政策法规的推进等等。同时，IPv6 与 IPv4 之间的兼容性也是一个重要的问题，需要通过技术手段和过渡机制来解决。 常见的 IP 协议渐进式迁移共存方案，主要有双栈（Dual Stack）、隧道（Tunneling）等技术。其中，双栈技术是目前业界应用较为广泛的一种 IPv4/IPv6 共存的一种技术，其目的是在互联网完全过度到 IPv6 之前，通过为设备安装 IPv4 和 IPv6 双协议栈。具有双栈的设备可以实现与单 IPv4、单 IPv6 或者双栈的设备进行通信。通过让各种协议栈能共存，渐进式地进行 IP 协议栈的迁移。像 Kubernetes 很早也已经对双栈功能进行了支持。 隧道技术是一种把 IPv6 地址封装到 IPv4 数据报中的方法，当数据从 IPv6 单协议栈发出后，在经过 IPv4 单栈网络环境的过程中，将 IPv6 地址封装到 IPv4 数据报作为 IPv4 数据报内容后，通过 IPv4 协议栈进行传输。在经过 IPv4 单栈环境后，来到 IPv6 单栈环境时，再将数据报中的 IPv6 数据段内容解析出来，构造新的 IPv6 数据报在 IPv6 协议栈环境中进行传输。\n# 微服务双栈迁移方案 上文介绍的方案更多的是一般化的方法论。但具体到微服务系统中，远程调用过程如何实现多协议栈共存以便帮助企业用户平滑进行协议栈的迁移呢？ 上图是当前业界微服务系统中服务之间普遍采用的远程调用过程架构图，本文接下来介绍如何基于双栈技术实现微服务应用的协议栈平滑迁移的常用方式。\n# 双注册双订阅实现协议栈平滑迁移 在微服务系统中，相比于单栈环境下，只有一个 IP 地址，微服务的注册与发现过程都基于该地址完成服务远程调用。在多协议栈共存的环境中，其本质就是要解决服务注册和发现过程怎么使用 IP 地址的问题。 梳理清楚了问题，就不难发现基于双注册双订阅的方法可以较好地解决微服务系统中多协议栈共存的问题，以便实现微服务系统协议栈的平滑迁移。该方案的服务注册和订阅过程可以被描述为下图所示： 采用双注册双订阅实现微服务系统平滑进行 IP 协议栈迁移的过程可以被大致描述为以下步骤：\n在新的应用升级或者发版之前，对相关微服务应用所在宿主机进行 IP 地址协议栈升级改造，让其同时支持 IPv4 和 IPv6 双协议栈。 经过步骤 1 改造的微服务应用，在微服务框架层面，通过一个双栈地址提取模块提取应用宿主机中有效的 IPv4 和 IPv6 地址，并通过服务注册模块，将双栈地址都注册到注册中心。 消费者订阅注册中心中的某个服务的 IPv4 和 IPv6 双栈地址，通过应用服务框架层面的双栈地址解析模块，比对宿主机所支持的协议栈类型，如果宿主机仅支持 IPv4 协议，则使用提供者的 IPv4 地址发起服务调用；如果仅支持 IPv6 或同时支持双栈，则用提供者的 IPv6 地址发起服务调用； 当系统中的所有微服务都完成支持 IPv6 协议栈的支持后，逐步对所有应用宿主机关闭 IPv4 协议栈，从而平滑完成大规模微服务系统从 IPv4 协议栈到 IPv6 协议栈的迁移。 # 基于 DNS 技术实现协议栈平滑迁移 双注册双订阅的方法虽然很自然和清晰，但是其由于服务注册过程中针对双栈环境中的应用会多注册一条 IP 地址对应的记录，会降低注册中心的服务承载量。 因此，也可以基于 DNS 技术实现多协议栈共存，解决微服务系统协议栈迁移的方法。其本质是将原来的注册服务实例地址过程变成注册服务实例域名（这里域名更多是实例标识作用），可实现在注册中心所注册服务实例记录数量不变的情况下，通过额外的 DNS 域名系统存储服务域名所对应的双栈 IP 地址，从而实现多协议栈的共存。采用该方案的服务注册和订阅过程如下图所示： 基于 DNS 技术实现微服务系统平滑进行 IP 地址迁移的过程可以被大致描述为以下步骤：\n在新的应用升级或者发版之前，对相关微服务应用进行 IP 地址协议栈改造，让其同时支持 IPv4 和 IPv6 双协议栈。改造后的应用需要将本机的双栈 IP 地址信息和本应用实例特点的域名注册到系统的 DNS 服务上。 完成域名注册后，应用实例将本地域名注册到注册中心。 消费者订阅注册中心中的某个服务所有实例的域名，通过应用框架层面的域名解析模块，向系统中的 DNS 服务发起基于域名解析请求，在通过 DNS 获取到示例域名对应的 IP 地址后，比对宿主机所支持的协议栈类型，如果宿主机仅支持 IPv4，则使用 IPv4 地址发起服务调用；如果仅支持 IPv6 或同时支持双栈，则优先使用 IPv6 地址发起服务调用； 当系统中的所有微服务都完成支持 IPv6 协议栈的支持后，逐步对所有应用宿主机关闭 IPv4 协议栈，从而平滑完成大规模微服务系统从 IPv4 协议栈到 IPv6 协议栈的迁移。 相比于双注册双订阅方式，基于 DNS 的方法可以较好地解决双注册双订阅过程中带给注册中心的多余压力，但 DNS 的高可用也是企业用户需要特别注意的点。\n# 实践 Spring Cloud Alibaba 作为应用广泛的微服务框架，目前在 2021.0.5.0 版本中已经提供了微服务场景下的不同协议栈应用互通共存方案，以便帮助企业用户实现大规模微服务系统的协议栈迁移能力。社区方案基于双注册双订阅实现，应用启动后会默认将微服务的 IPv4 地址和 IPv6 地址注册到注册中心中，其中 IPv4 地址会存放在 Nacos 服务列表中的 IP 字段下，IPv6 地址在 Nacos 的 metadata 字段中，其对应的 Key 为 IPv6（可以解决普通双注册双订阅过程中的同一个服务实例有两条记录，对注册中心造成压力的问题）。当服务消费者调用服务提供者时，会根据自身的 IP 协议栈支持情况，选择合适的 IP 地址类型发起服务调用。具体规则：\n服务消费者本身支持 IPv4 和 IPv6 双协议栈或仅支持 IPv6 协议栈的情况下，服务消费者会使用服务提供的 IPv6 地址发起服务调用； 服务消费者本身仅支持 IPv4 单协议栈的情况下，服务消费者会使用服务提供的 IPv4 地址发起服务调用。 # 应用配置 相比于一般使用 Spring Cloud Alibaba 构建微服务，要使用协议栈共存迁移功能需要对应用增加如下配置：\n# 服务注册 目前，使用支持协议栈共存迁移功能的 Spring Cloud Alibaba 版本以后，服务提供者在进行服务注册过中，不需要做任何配置，会默认检查当前应用所支持的协议栈情况，如果默认是单 IPv6 或 IPv4 协议栈，则仅注册相应的地址。如果应用支持双栈，则会自动获取应用的 IPv6 地址，然后，将 IPv6 地址作为应用实例的服务示例元数据注册到注册中心上。\n# 服务消费 如果应用是采用 Spring Cloud Alibaba 2021.0.5.0 版本，默认使用 Spring Cloud LoadBalancer 负载均衡策略，需要在消费者应用 application.properties 配置文件中增加如下配置开启协议栈共存迁移功能：\n1 2 spring.cloud.loadbalancer.ribbon.enabled=false spring.cloud.loadbalancer.nacos.enabled=true # 效果演示 为了便于演示，本文直接基于阿里云容器服务 ACK构建了一个双栈环境，来进行双栈环境的服务注册与消费演示。\n# 服务注册 如下本文演示用的服务提供者实例 Pod 信息： 基于 Spring Cloud Alibaba 协议栈共存迁移功能，其在注册中心上的服务实例列表信息： # 服务消费 单栈环境服务消费者： 服务调用成功以后，服务提供者会打印调用消费者的调用 IP 地址： 从上述返回结果来看，IPv4 单栈环境中的消费者由于仅支持单栈，所以一直通过 IPv4 协议栈向双栈服务提供者发起请求。 双栈环境服务消费者： 服务调用成功以后，服务提供者会打印调用消费者的调用 IP 地址，可以看到打印的是消费者的 IPv6 地址： 从上述返回结果来看，IPv4/IPv6 双栈环境中的消费者由于支持 IPv6，为了实现协议栈向 IPv6 的迁移，所以默认一直通过 IPv6 协议栈向双栈服务提供者发起请求。\n","date":"2023-01-03T12:00:00Z","image":"https://xiuwei.github.io/p/ip-protocal-migration/cover_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/ip-protocal-migration/","title":"Spring Cloud应用如何平滑迁移至IPv6?"},{"content":" # 1. 前言 在阅读之前，先统一概念称呼。对于平台，本文统一用aPaaS（应用平台即服务，application Platform as a Service）泛指包含零代码、低代码、iPaaS（集成平台即服务， integration Platform as a Service）等技术的PaaS开发平台/开发工具。而对于技术方向，还是区分为零代码、低代码。\n本文主要记录我对aPaaS相关内容的思考和观点总结，其主要根据我的项目经验和行业观察学习而来。这些思考主要为了回答以下问题，欢迎交流讨论：\naPaaS目前发展遇到什么问题（困境）？能否解决？\n在这些困境之下，aPaaS价值几何，是否值得继续投入？\n为了最大化实现价值，aPaaS的发展趋势是什么？\n在这种发展趋势下，aPaaS的重点模块可以如何做？\n# 2. 当前困境 # 2.1 客户现状 1）大部分客户更想要解决方案，而非单纯的工具（不想用）\n客户首要关心我们是否帮助他们准确地发现问题、快速高效地解决问题。只要能解决问题，用Excel都可以。 所以，客户是否需要aPaaS，关键在于我们能否为其提供切实可行的数字化转型、升级的解决方案（要包含如何使用aPaaS深度参与）。\n也就是，aPaaS不一定适合所有行业的企业的生命周期各个阶段、业务生命周期各个阶段。但如果aPaaS要作为企业的方案候选项，就应该尽可能在不同阶段的痛点上有突出优势/定位，而不是一味地宣传降低代码量。例如对于中小企业的业务起步阶段，aPaaS可以帮助企业低成本地快速试错。\n解决思路：咨询服务+行业解决方案（基于aPaaS的行业全价值链的解决方案，可供单独环节使用）+行业级应用模板\n2）客户对aPaaS不信任，担心受限受控（不敢用）\n2.1）aPaaS强依赖供应商（锁平台）。 目前，aPaaS主要通过解析引擎解析用户的配置让应用跑起来。配置和解析引擎缺一不可，而不同厂家的配置方式不同、解析引擎不同，互不兼容。客户如果想更换产品服务，就要付出巨大成本。\n而且，同为绑定锁平台，与SaaS的开箱即用不同，aPaaS还需要额外付出配置成本，绑定影响更深。这些都让客户的研发受限于aPaaS能力，受控于供应商。\n2.2）aPaaS的各种标准和规范尚未完善。 与成熟的软件开发模式不同，aPaaS的权责边界尚不清晰，且各种功能缺乏透明度，缺少监管。这让aPaaS存在商务纠纷风险。例如版权问题，客户使用aPaaS配置的应用，软著属于谁？\n解决思路：发展的问题在发展中解决。这需要aPaaS自身、业界共同发展才能解决。也侧面证明aPaaS业界还在激烈斗争期。\n3）采购aPaaS的交易成本大（不会买）\n3.1）难以选型。 目前，业界的aPaaS同质化严重，差异化不明显。各个aPaaS缺乏大量且长久的实践经验和数据，导致客户难以量化价值。而且市场也无相关选型报告。\n3.2）决策压力大。 客户担心aPaaS是否又一个数据孤岛，能否兼容老旧系统、以及未来的新系统。如果“一购定终身”，那客户的决策压力非常大。\n解决思路：整体发展+突出卖点、案例报告+生态化\n4）大部分客户还较难充分使用aPaaS（用不好）\n4.1）业务人员能力差异大。 零代码aPaaS主要面向业务人员。现阶段，大部分业务人员连清楚表达需求都较难做到，要他们使用aPaaS准确抽象出业务场景和流程就更难了。而且，部分aPaaS的易用性不够，更提高了学习成本，加剧业务人员的工作负担。\n4.2）缺少开发者。 低代码aPaaS主要面向开发人员（包含专业实施人员、初级程序员、高级程序员）。如果客户没有正式的IT团队或实施团队，他们很难使用低代码aPaaS产出期望结果。而且团队组建并非一朝一夕之功，让团队熟练使用低代码aPaaS也非易事。\n解决思路：整体发展，加强aPaaS的易用性和功能性，提高数字化建设ROI。\n# 2，2 产品自身问题 在业界内，aPaaS（特别是低代码aPaaS）被很多使用者和开发者称为“KPI项目”，是忽悠老板和投资人的毒瘤。\n我认为，aPaaS的问题主要是以下几点：\n1）无法满足典型场景的复杂需求\n目前，零代码、低代码的底层是声明式编程的DSL（领域特定语言），因此它们继承了声明式编程、DSL的优点和缺点。（声明式编程：描述要做什么（what），至于如何做（how）交由引擎解析执行。\n例如SQL就是经典的声明式编程的DSL）。基于零代码/低代码的aPaaS目前只适合满足在特定领域里的需求，不适合所有场景，这是声明式编程、可视化DSL的天然缺陷。但客户的需求不会只局限于特定领域。\n现在的aPaaS无法满足有传统开发的典型场景需求，例如跨业务系统对接需求、复杂逻辑需求、行业特色需求等。为了项目交付，这种天然缺陷必然要有解决方案。\n2）功能性（颗粒度）与易用性的矛盾（主要矛盾）\n根据软件工程理论，工程的本质复杂度无法避免，没有银弹。工程理论主要解决附属性工作产生的次要复杂度（人为引入复杂度，如编程）。当次要复杂性无限接近0，就是理想中效益最大化。\n降低次要复杂度的有效途径是封装复杂度。当封装的颗粒度越细时，越适合更多场景，越实用。而最细颗粒度的封装是各种专业编程语言、知名脚手架。\n易用性是面向广大普通用户而言的，而非专业程序员。颗粒度越细，普通用户使用门槛越高，丧失低代码的初心。\n3）成本问题（次要矛盾）\n对于开发商，理想的aPaaS是颗粒度足够细，又足够易用，这需要巨大的研发成本才能找到符合产品定位的平衡。而对于客户，颗粒度足够细的高代码用不起，所以追求易用的aPaaS。\n4）难以对抗熵增\n软件在整个生命周期中会不断熵增，表现为需求变更、功能变多、数据变多、性能变慢等。如果不人为干预进行降熵，软件就会逐渐腐烂（software rot），直至出现故障、无法使用等。而aPaaS的对抗熵增能力有待提高，具体表现为：\n4.1）封装限制了潜力。 相比较通用编程语言，零代码、低代码为了降低复杂度，牺牲了拓展性和潜力，最大转化降本增效价值。这是天然缺陷。\n4.2）功能缺失造成对抗困难。 次要复杂度不只包含开发编程，也包含测试、迭代、运维等全生命周期的人为工作。而目前大部分aPaaS的抽象封装重点是开发阶段，忽略其他阶段，没有考虑整体上降低复杂度。\n4.3）客户无法独立对抗熵增。 aPaaS运维分为两部分：aPaaS自身迭代运维、配置应用的迭代运维。对于客户，他们能利用aPaaS自身的运维工具对配置应用进行运维，但对aPaaS自身无能为力。如果aPaaS厂商缺乏及时快速的支持，那客户对抗熵增能力极差。\n4.4）滥用定制化。 为了项目交付，部分产品会放弃抽象封装，不断增加定制化组件。这种组件作为独立小模块，很难融合到大一统体系，加剧了系统熵增。\n# 3. 定位和价值 要最大化价值，就要找到PMF，找准定位。\n# 3.1 定位 # 3.1.1 目标行业 1）B端\naPaaS可以面向B端全行业的所有企业。最简单的原因是，中国的程序员缺口非常大。\n同时，根据调查，目前aPaaS在以下行业的渗透率较高，可以针对性发展：通信、金融（银行、保险）、能源、医疗、房地产、制造、教育、零售等行业。这些行业的共性是：用户量大，个性化需求多。可以再细分成两种：\na）具备一定垄断性质的行业。这些行业的业务流程明确、数据量大。而且，他们利润较好，付得起目前aPaaS的前期培养成本，又处于新时代升级阶段。例如通信、金融等。\nb）政策扶持或劳动密集型的行业。如制造业、教育业。\n另一个方向就是出海，国外的人力成本比国内高很多，aPaaS能更好地发挥价值。\n2）高校\n面向高校可以重点发展产学研一体化。\n对于学校，因为低代码aPaaS本身就是抽象并可视化软件开发过程，所以有利于学生快速掌握开发思维和开发流程。同时也提供项目平台，方便学生从项目落地实践中学习编程。\n对于aPaaS供应商，既可以收集使用数据反哺迭代，也能丰富社区产出。\n对于企业客户，高校培养的零代码、低代码人才可以让企业更好地组建实施团队。\n3）G端\naPaaS可以面向政府里对服务效率、服务体验要求高的部门。\n这些部门一般业务流程明确、功能规范明确，非常适合使用aPaaS打造安全、高效、统一的服务体系。但政府端的产品由于服务各种终端的用户、与多部门协作、数据敏感等多种特性，更重视产品的多平台、兼容性、开放性、稳定性和安全性。这对aPaaS提出更高要求。\n# 3.1.2 目标客户 aPaaS主要面向有数字化转型、升级需求的客户。根据客户的数字化程度，aPaaS有着不同的细分客户：\n1）无数字化经验的客户，一般是小微企业。主要需求是数字化转型，快速拓展市场。\n2）有一定数字化经验的客户，一般是中小企业。主要需求是数字化升级，寻找第二增长曲线，同时解决数字化死角。\n3）有丰富的数字化经验的客户，一般是中大型企业。主要需求是深化数字化改革，加强精细化运营、打破数据孤岛。以求帮助寻求业务迭代和创新机会，帮助进行战略布局。\n而具体到客户内部，零代码aPaaS主要面向业务人员，低代码aPaaS主要面向专业开发者（包含程序员、专门的实施人员）。\n# 3.1.3 目标场景 根据aPaaS的能力定位不同，目标场景主要有4种：\n1）面向通用型业务场景，普适发展型。面向行业属性较低的通用型场景，主要是企业OA管理。或者基本CRUD场景，主要是简单逻辑的业务。该场景一般是零代码aPaaS产品。例如简道云、明道云、airtable等产品。\n2）面向垂直型业务场景，领域服务型。针对专一领域，深度挖掘领域业务场景，提炼领域共性特征，提供领域专用的功能模块或专用解决方案。例如物联网领域的物模型、告警引擎等，以及常见的电商、CRM领域的有赞、销售易、纷享销客等。\n3）面向综合型业务场景，产品研发型。面向复杂业务场景，同时兼容通用场景。主要满足大型软件、或打造企业内外生态需求。例如mendix、outsystem、华为Astro、微搭、宜搭等产品。\n4）面向B端所有场景，创新先驱型。未来aPaaS的重点定位。可以面向通用、垂直、复杂等场景。因为全面、专业、智能、成熟的aPaaS能与专业研发体系无缝融合，真正做到让业务管业务，让技术管技术。\n# 3.1.4 产品形态 1）开发工具\n根据使用者不同，有两种应用方向。\n1.1）专业开发的辅助工具。低代码aPaaS作为专业开发工具，支持code-in \u0026amp; code-out，支持无缝与专业研发体系融合。开发团队在项目工程里使用aPaaS提高开发效率。也就是，低代码aPaaS只是开发阶段的拼装环节，最终还是输出源码进行部署。相当于把aPaaS作为代码生成器或者说中台。\n1.2）产品的高级能力。aPaaS作为一种能力附加在产品上。客户可以一定程度上调整产品的标准化功能，或者在平台上增加个性化功能。主要为了解决SaaS产品的标准化功能与客户个性化需求的冲突。例如纷享销客、销售易、有赞等厂商的产品。\n2）开发平台（主流）\naPaaS作为独立开发平台，支持客户在平台上实现应用全生命周期管理，包含设计、开发、测试、部署、迭代和运维等。\n# 3.2 价值 B端产品的价值体现，最关键的是降本、增效、创收这三方面。总结来说，目前aPaaS主要价值是帮助企业数字化初期快速探索和试错，以及数字化运营期间解决员工与业务、公司与客户的“最后一公里”问题。 而当aPaaS发展成熟后，能作为真正的创新先驱型产品时，aPaaS主要价值是深入并赋能企业全域全价值链的数字化，是企业研发的C位，而不仅局限于打辅助。具体的价值如下，这些价值足以值得继续投入发展：\n# 3.2.1 降本 降本要分析降的是什么本，只有弄清楚“是什么”，才能知道缺什么，下一步“如何做”。aPaaS的降本主要有几方面：\n1）机会和试错成本\n企业在拓展市场、探索新业务时，需要不断选择机会、试错，直至发现正确道路。而aPaaS可以帮助企业最小化机会成本，降低试错成本。\n1.1）快速响应机会，快速试错，避免错失良机。由于aPaaS开发效率高，响应快、初期投入少（业务人员就可以配置），同样的资源可以响应更多机会、尝试更多次。\n1.2）量化验证、复盘分析。试错关键是量化验证、复盘、方向调整。即要知道是否错、错在哪、如何处理。aPaaS帮助企业自定义监测，量化业务效果。当发现效果不佳，复盘分析原因，然后调整执行方案、及时停止或选择其他机会。\n例如：企业通过aPaaS配置demo给客户验证，效果合适再重点投入。\n2）时间成本\naPaaS可以帮助企业降低项目实施的时间成本，包含从0到1，以及从1到优的迭代运维阶段的时间成本。\n3）人力成本\naPaaS可以帮助企业降低研发团队的人力成本。\n3.1）降低初期投入人力成本。数字化转型初期，企业可以使用业务人员或初级开发者探索和试错新机会。当新机会的商业模式跑通后，也明确知道想要什么时，企业可以再采用高代码重构平台。避免一开始就要维护高成本的专业IT团队。\n3.2）降低维持专业IT团队的人力成本。aPaaS可以帮助提高开发效率，且具备应用全生命周期管理。能在很长一段时间内，降低了全周期需要的专业程序员数量，也降低了程序员能力要求。\nSaaS也可以降低人力成本，区别在于aPaaS的个性化效率更高。（所以目前很多SaaS也增加aPaaS能力以弥补效率问题）\n4）拓展成本\naPaaS可以帮助企业降低软件的拓展成本。主要表现为：\n4.1）降低系统迭代成本。企业可以通过aPaaS对系统进行修改优化，减少定制外包的拓展成本。\n4.2）降低构建生态成本。企业如果存在老旧系统，在采购新系统时，就需要支付集成拓展成本，以便让新系统融合老旧系统。或者需要与其他企业的系统协作时，也需要支付集成拓展成本。而aPaaS可以帮助企业降低连接新老系统的集成拓展成本、企业内外生态的集成拓展成本。\n# 3.2.2 增效 1）研发效率\n1.1）提高全生命周期的研发效率。产品发展成熟后，aPaaS不仅仅提升开发效率，更可以提高企业的设计、测试、部署、迭代和运维阶段的工作效率。\n1.2）提高业务与开发的沟通效率。业务人员可以通过aPaaS可以深度参与应用搭建，这种圆桌式开发可以帮助团队保持共识。\n2）业务工作效率\n除了数字化带来的工作效率提升，aPaaS主要提高了一线员工的业务工作效率。\n2.1）快速满足员工与业务“最后一公里”。一线员工在处理业务时会产生大量优化小需求。这些多变、简单、个性化、长尾需求可以说是员工与业务的“最后一公里”。一般情况下，企业自身的IT团队、SaaS供应商或外包无法快速响应。企业的实施团队或一线员工通过aPaaS搭建各种微应用快速满足需求。\n2.2）提高跨公司业务协同效率。aPaaS通过iPaaS能与其他企业建立生态关系，以便跨租户跨公司进行业务协同。\n3）服务效率\n在服务客户过程中，客户也会产生大量优化需求，也就是员工与客户的“最后一公里”。这种需求也可以通过aPaaS快速解决，从而提高服务效率。\n4）决策效率\n数字化与信息化的最大区别在于数字化可以闭环，从数据产生、数据流转到数据分析与决策，让数据真正活起来。aPaaS通过构建企业生态环境，采集并治理企业内外系统数据，满足企业个性化的BI需求，可以最大程度帮助企业提高决策效率。\n# 3.2.3 创收 1）直接收入\n企业利用aPaaS的产出得到的收入就是直接收入。例如，aPaaS供应商卖aPaaS给企业，企业再使用aPaaS开发应用，然后将应用卖给客户。 适用于外包、ISV，以及将软件作为增值服务的企业。例如，客户购买了设备，可以同时购买设备管理平台。\n2）间接收入\naPaaS不仅仅是一个工具平台，更是一套数字化变革方案。这种方案会让企业变革工作模式、管理模式、商业模式等。企业利用aPaaS完成数字化转型、升级，最终找到新的增长曲线。这种收入就是间接收入。\n# 4. 产品发展 aPaaS发展主要有两个方向：易用性、功能性。也就是多快好省，提高软件全生命周期的ROI。这两个方向的发展具体表现以下几个方面：\n# 4.1 aPaaS本质 新时代是数据时代，数据就是信息，而提取信息里的规律就能预测未来，把控个人和企业的未来发展。aPaaS的本质是方便普通人对数据的生命周期管控，包括数据产生、收集、管理、分析、流转。也就是aPaaS是普通人在数据时代的车票，避免被时代抛弃。\n# 4.1 全域化 1）概念\n全域化有两种方向：数据全价值链、软件全生命周期。数据全价值链是指aPaaS能帮助企业高效使用数据资产，包括数据产生、收集、管理和利用等环节。软件全生命周期是指从需求、设计、开发、测试、部署、迭代和运维的全流程都可以在aPaaS上完成。\n2）趋势原因\n2.1）降低体系复杂度。整体降低软件次要复杂度，而非只降低单一环节，提高与纯代码研发的竞争力。\n2.2）高效全面协同。全面云上一体化，让业务、产品、设计、研发、测试和运维等团队能跨时间、跨空间高效协同。\n3）方案想法\n详见5.2章节：应用全生命周期管理。\n# 4.2 智能化 1）概念\n智能化就是aPaaS+AI，旨在用AI帮助用户快速上手，提高实施人员的配置效率，提高应用的使用效率，以及帮助企业优化业务。\n2）趋势原因\n2.1）追求易用性是基本目标。从机器语言到汇编语言，从汇编语言到高级语言，人类从未停止对编程易用性的追求。而AI是否能降低编程门槛，正在积极探索中。但希望很大，正如AI绘画让更多没有绘画基础的用户能产出不错的画作。\n2.2）提高效率。智能化可以让用户更快地配置应用，而且能让人真正从标准、重复枯燥的工作中解放。\n2.3）赋能业务。AI可以帮助企业更全面、深入、持久地审视数据，发现优化点，真正赋能业务。\n3）方案想法\n3.0）本质思考\n利用AI拓展“适用场景的范围”，也就是：允许无规则输入，转化为有规则的输出\n第一阶段：限制有规则的输入。 让用户先自己理解完，再输入。这一步如果无法实现，直接跳到第二步很难。\n例如：要销售手动填线索单、或者让采购手动填采购明细单。又例如：自动生成JS事件，用户用特定语句输入，系统后台自动转化为脚本。\n第二阶段：利用AI的理解能力，扩展输入范围。 也就是把“让用户理解”的任务交给AI。\n例如：销售直接自然语言描述，AI理解后自动对应规则字段。或者采购给出原始的采购明细单，AI理解自动对应标准字段。又例如：用户用自然语言输入，系统就能生成相应脚本。\n3.1）AI辅助配置\nAI自动生成模块、应用、BI图表还在探索阶段。以下是我的想法：\na）在aPaaS自带的原型平台上画原型和流程图，然后AI直接根据原型生成数据模型、页面及其事件动、流程等内容。（如果是单纯的CRUD页面，不用AI也能生成了）\nb）约定好PRD格式规范和语句规范，AI根据PRD自动生成数据模型、页面及其事件动作、流程、API等内容。或者参考figma，设计专门的PRD功能，边写PRD边生成。\nc）终极目标是自然语言编程。AI根据业务人员的自然语言直接生成模块或BI图表。\n3.2）AI辅助使用\nAI辅助用户使用配置平台或应用，使工作更有效率。\n例如，参考ChatGPT，通过对话可以生成相关代码。那AI的应用场景可能是：通过与AI对话，生成所需代码，直接粘贴到配置页面就可完成复杂功能配置。\n或者，AI根据客户需求智能推荐字段，避免业务人员一无所措。\n又例如，在移动端上，用户直接文字或语音询问系统某个功能，或者查询某条数据。或者通过问答对话形式生成临时BI图表。\n3.3）AI辅助业务优化\n通过流程挖掘技术，AI可以帮助企业定位业务流转的“堵点”，以便企业针对性地优化调整业务方案（包含业务执行方案、aPaaS配置改动等）。\n# 4.3 垂直化 1）概念\n垂直化是指aPaaS为细分行业客户提供特有功能模块或解决方案。但垂直化并不意味着停止发展通用化，为了更好的ROI和更大的市场，追求一种“协议”通用是很正常的，详见4.4章节的专业化。\n2）趋势原因\n2.1）行业经验是B端产品的有效且牢固的产品壁垒，也是重要的差异化。\n2.2）针对垂直行业的抽象封装会更为准确，能满足客户的核心需求，而非停留在通用层次。\n2.3）功能性深入发展的具体表现。越垂直，越深入，这种时候，垂直化模块会成为一个“库”，不但aPaaS能用，专业研发体系也能用。\n3）方案想法\n3.1）官方或ISV提供垂直化模块和解决方案\n官方或ISV在aPaaS的生态市场上提供垂直化物料，包含组件、连接器等。以及提供垂直化解决方案，包含应用模板、工作流程、完整方案文档等。\n例如针对物联网领域，aPaaS可以提供iot物料（物模型、告警引擎、iot连接器等）、组态可视化、售后知识图谱等行业模块。\n# 4.4 专业化 1）概念\n专业化是指让零代码、低代码要更加专业，能真正降低复杂度，而不是玩具。要能与专业的编程语言相比较，真正具备新一代编程语言风范。而非简单的拖拉拽可视化编程，低代码并不low。例如要有自己的思想内核、有体系、有规范。\n2）趋势原因\n2.1）专业化才能真正提高易用性，降低学习门槛。专业地抽象封装，才能有效降低复杂度。\n2.2）专业的语言才能研发出专业的软件，真正解决需求，而不是研发出一个玩具。\n3）方案想法\n3.1）零代码是业务语言编程的DSL 对于业务人员，如果要重新学习程序思维和程序知识，那零代码的使用难度还是太高。\n所以我的想法是，零代码应该是一种以业务思维为核心，以业务语言进行声明式编程的DSL。也就是从业务侧出发，将代码逻辑封装成具体的业务语言模块，再设计可视化交互。与中文编程易语言比较，零代码只能面向特定领域，灵活性更低但更易用。\n具体表现为通过可视化编排，告诉系统在某个业务的每一步工作内容，然后交由系统解析执行。\n未来，更进一步就是自然语言的AI编程了。\n例子：用户不用按代码那样写循环，只需要告诉系统要对哪些数据做什么内容。例如将某些数据里符合条件的数据的状态字段改为1，系统会自动解析执行循环。\n3.2）低代码未来方向仍在探索中 低代码主要面向开发者（包含程序员、实施人员），仍然是程序思维。现阶段低代码是将代码语言可视化的DSL。可视化的实体能降低抽象思维能力，帮助用户更易理解、沟通和编排。同时，可视化一定程度上降低了门槛，让初级开发者能越级承担部分高级工作。\n可视化是现阶段低代码DSL的解决思路，但绝不是未来。因为从功能性出发，最有效的复用是引用库，库实际上就是一种低代码。而从易用性出发，就必须明白现在的代码有什么困难之处，才能将困难封装起来，形成一门新的dsl，甚至通用编程语言。这需要非常深入的研究，例如当初java的诞生就是因为c++不能跨平台。\n低代码的未来仍值得继续深入研究。\n# 4.5 生态化 1）概念\n生态化是指aPaaS覆盖或连接企业管理全域、业务全价值链，帮助企业构建内外统一的数字化生态。\n2）趋势原因\n2.1）aPaaS需要内循环，才能有效赋能企业生态建设。\n2.2）互联互通是数字化基本要求。生态化可以帮助企业打破内外数据孤岛。\n2.3）当产业链上的企业们共同完成数字化转型升级，企业的效益才能最大化。\n3）方案想法\n3.1）aPaaS自身内循环生态\n构建应用模板生态、物料生态，尽可能覆盖更多场景，提高用户配置效率。\n3.2）企业内外生态（产业链生态 / 价值链生态）\n通过跨平台（web、APP、小程序等）+iPaaS+跨租户业务协同等功能，打通企业内部各系统、企业外部各系统。同时，通过BI功能，帮助企业分析内外生态数据，辅助决策，形成闭环。\n# 4.6 兼容化 1）概念\n兼容化是指零代码研发体系、低代码研发体系、高代码研发体系相互兼容，三者混合研发。\n2）趋势原因\n2.1）三者互补，保障项目交付，保障应用生命周期正常。零代码、低代码作为DSL，必然存在不适用的领域。零代码、低代码、高代码三者互补，可以保证满足业务需求，保障项目的交付以及后续迭代运维。\n2.2）体系建设和拓展成本低。兼容化可以让aPaaS与当前专业研发体系无缝融合，无缝兼容旧物料，避免重复解决问题。\n2.3）资源价值最大化。让业务人员、初级开发者、高级开发者做符合能力的工作，共同为同一产品付出。\n2.4）保障生态统一。企业数字化要求互联互通，统一管理生态。三者兼容可以让企业内外的系统更易对接。\n3）方案想法\n3.1）零代码（no code）与低代码（low code）\n同一平台的零代码、低代码，底层可以都是模型驱动。这样保证底层逻辑相同，天然地支持互相调用。只是零代码与低代码的抽象角度不同，配置逻辑和交互有所不同。\n3.2）低代码（low code）与高代码（pro code）\n低代码与高代码相互兼容有几种形式：\na）物料+微服务\n在aPaaS上，高代码可以利用云IDE或本地IDE研发物料或者微服务，实现即插即用。\n配置的物料与高代码物料支持相互调用。最终共同发布到同一服务器。物料一般包含前端组件、区块、页面、后端插件等。\nb）在线代码拓展（内嵌）\n直接在aPaaS上编写代码，实现复杂功能。例如，页面配置时，没有合适的动作事件，就可以通过代码形式实现。或者配置API时，可以调用代码块节点实现复杂逻辑。\nc）code-in \u0026amp; code-out\n支持输入源码（主要是组件源码），然后在aPaaS上将源码可视化，允许用户拖拉拽配置。\n支持输出源码，有两种方向：开发环境输出代码，相当于代码生成器，缺点是二开后不可逆。\n另一种方向是在服务端实时生成源码，即不经过解析引擎解析，直接以源码运行。\n# 5. 部分模块简析 # 5.1 概述 在aPaaS项目里，产品经理的主要职责是抽象业务场景和软件开发过程，并输出功能模块的业务逻辑和交互设计。产品经理可以不会代码编程，但要知道编程有什么输入输出。例如，告诉技术要开发哪些组件，每个组件的配置属性、交互怎么样。\n我的主要设计方法论是：IPO模型（输入-处理-输出）+数据流转路径。 数据只有流转起来，系统才是活的，输入输出要考虑上下游。同时，用拆分思维从上往下、或从下往上分析对象每层的IPO。\n1）输入。输入什么、输入从哪里来、什么时候输入、如何更容易更快更准确地输入等5w2h问题。一般来说，需要结合业务场景和软件技术，封装设计时才知道要对外提供哪些输入，可以隐藏哪些细节（隐藏细节不代表不做，而是做好不给改）。\n2）输出。输出什么、如何更快更准确地展示输出、输出到哪里、什么时候等5w2h问题。\n3）处理。即如何实现输入向输出转化。根据拆分层次，越靠近底层，代码思维会越多。拆到最底层时，就是研发封装处理逻辑的代码。\n而在业务项目里，产品经理主要是抽象业务场景，并输出设计。这种思维与零代码是一致的，产品经理输出的PRD，就像一份声明式编程，告诉程序员要做什么，然后程序员解析如何实现。\n# 5.2 应用全生命周期管理 应用全生命周期管理是支持软件的设计、开发、测试、部署、迭代、运维的一体化服务管理能力。也是全栈化的核心模块。\n1）设计\n1.1）战略设计-领域建模\n领域模型是表达业务实体及其逻辑的一种统一语言。领域建模就是构建业务领域，以及领域内的业务实体、业务行为、业务关系。是一种业务抽象的具象化表现。\n后续开发阶段，数据建模时就可以根据领域建模构建ER图，然后构建数据表。\n对于简单的系统，可以直接跳过战略设计。对于复杂系统，零代码、低代码都可以使用领域建模进行战略设计，然后再搭建应用。目前，领域建模还是文档资料，承担沟通、辅助理解等作用，尚未完全与其他阶段融合一体化。\n1.2）产品战术设计-思维导图、原型、流程图、UI图、PRD等 具体落地设计的文档主要支持本地上传和在线浏览。开始智能化后，在线画原型或在线PRD将会成为关键。\n2）开发\n目前aPaaS配置的应用可以采用三层架构：表现层、业务逻辑层（BLL/service）、数据访问层（DAL/DAO），对应的主要模块是页面-API和流程-数据建模。而在对于表现层页面，前端可以采用MVC或MVVM架构。\n对于零代码的业务语言编程，实际上只有页面-工作流（API逻辑和流程逻辑混合）。\n未来可能会有更符合零代码、低代码的架构出现。例如DDD架构（领域驱动设计）就很有潜力。\n3）测试\n3.1）沙箱环境\n提供沙箱环境给用户测试配置应用。用户配置应用后，直接点击“预览”即可进入沙箱环境调试应用。\n同时，支持将部分生产数据同步到沙盒环境，以便更好地测试。\n3.2）自动化测试\nUI自动化测试：利用RPA配置页面自动化测试用例。\nAPI自动化测试：与API模块结合，为每个API配置用例（输入、比较值），同时配置用例执行规则。\n测试日志：查看自动化测试用例执行结果。\n3.3）在线调试\n在线实时地输入模拟参数，系统输出模拟参数，观察出参是否期望结果。可以用于流程仿真、逻辑仿真、脚本调试、连接器调试等地方。这些场景本质上就是入参和出参。\n4）部署\n部署主要分为初次部署和升级部署。应用初次发布/部署是相对简单的。而升级部署需要考虑变更内容对生产数据的影响。例如提供升级差异比较功能，展示所有影响条目。\n同时，应用还可以支持独立部署，即单独作为一个系统使用，而不依赖于应用平台入口。\n5）迭代和运维\n5.1）版本管理。管理应用版本，支持版本对比。最好支持回滚，但由于涉及数据问题，没有很好的封装方案。除了应用版本，对于数据建模、页面、API、流程、连接器等功能模块都需要版本管理。\n5.2）引用关系。引用关系是在建模、页面、API、连接器等模块里，支持查看各元素的引用关系，包含引用了哪些数据表、API、节点参数等。例如当修改某个字段/API时，可以快速定位所有引用地点，确保功能修改完整。\n5.3）日志管理。管理前端组件、后端API、连接器、集成流等各种模块的运行日志。日志可以具体到各个节点的出入参，方便开发和运维定位问题点。\n5.4）源码。支持输出应用的源码，方便二开。但这种目前做不到可逆，即还无法做到从源码转换回aPaaS的配置。\n5.5）管理基础设施。管理数据库、各种服务器等底层基础设施。\n5.6）运维监控。可以通过埋点采集、BI和iPaaS等模块，进行自定义运维监控。\n# 5.3 数据建模 数据建模本质是抽象业务实体及其数据特征，构建数据表以及表之间的关系。可视化表现为ER建模或普通表格式建模。如果已经存在领域模型，也可以直接根据领域构建数据模型。\n模块设计：\n1）输入\n输入什么：表关系、字段（普通字段、引用字段、外键字段、动态字段、系统内置字段）、索引等内容。细化一层，需要设计每种字段的输入（各种约束属性）、输出（数据表表头字段）\n输入方式：手动新建，或者批量导入。\n2）输出\n输出什么：数据表\n输出怎样用：根据架构，需要定义DAO层服务以访问数据库。（通过配置定义DAO层服务，又是另一个输入输出了）\n输出用到哪里：通过引用关系功能，可以查看该字段被哪个页面、API等模块使用。\n3）处理\n将字段表和DAO层配置转化为数据表以及封装的DAO层服务。\n对于零代码，业务人员不需要关心这种底层，只需要构建页面（表单页面建模或者多维表格建模）。保存页面后，页面的字段会自动转化为数据模型。\n如果低代码要调用零代码的数据模型，可以进一步管理DAO层服务。\n# 5.3 页面设计 B端产品的页面本质是根据场景，让用户高效输入数据，经过前后端处理后，将输出数据以合适的形式展示出来。\n页面设计是前端编排的重要模块。页面的主要设计架构是MVC或MVVM。与MVC的区别在于MVC是页面与前端模型单向绑定，而MVVM是双向绑定（页面与前端模型自动同步，可以更快地响应）。\n模块设计：\n1）输入\n输入什么：将组件拼装。细化到组件层，根据业务场景和架构，可以抽象出多个组件及其属性，而组件属性主要有几种大类：前端模型（M）、展示样式和布局（V）、业务逻辑（VM，包含动作事件、自动填充等逻辑）。\n如何输入：手动拖拉拽前端模型的字段或空白组件字段，或者导入Excel自动生成\n2）输出\n输出什么：应用页面。对于零代码，还会输出数据模型（属于间接输出，因为只是触发生成）\n输出如何展示：支持配置不同页面形态展示输出。例如表格、思维导图、甘特图、看板等形态。\n输出会用到哪里：页面可以与菜单绑定、被事件调用展示，或者通过分享功能对外公开等。\n3）处理\n将解析代码封装成引擎，将用户的配置解析渲染为真正的应用页面。\n# 5.5 流程编排（BPM） 流程（BPM）的本质是：人为规定的有序工作路径，规定每一步由 “谁（who）” 在 “什么时候（when）” 、“什么场景（where）” 应该 “做什么事（what）”，“怎样做（how）”。\n对于低代码，流程编排是以只对业务流进行编排（一般称为审批流），不包含API。而对于零代码，流程编排实际上是工作流编排，融合了流程和API。\n对于流程，我采用从下往上的封装方法。从业务场景抽象出本质，分析流程细节，然后根据常用的业务场景和BPM规范封装一层，就可以得到具体的流程节点。流程细节如下：\n1）有序工作路径\n路径有开始、有结束、有流转方向、也有分支。具体可封装成开始、结束、判断、分离/合并等路径控制节点。\n2）谁\n当前步骤/节点的任务由谁去做。所以需要选择对象。对于低代码，一般对象范围是企业内外的用户（技术思维，流程与API是两个东西，不混在一起编排）。对于零代码，对象范围是用户或系统（业务思维，人做或系统做都是业务工作流的一部分）。\n选择用户对象的方法：从组织架构树选择企业内部或外部的具体用户、选择某个群体（角色、用户标签、部门等）、表达式计算（通过参数计算当前节点）、关系链（通过组织关系链找到具体用户，例如流程发起人的部门经理）。\n表达式和关系链实际上都是让系统自动计算出用户，免得用户手动选择执行人，使用体验更好。\n3）什么时候\n当前步骤/节点的任务在什么时候要做。具体可表现为定时做（周期/非周期）、即时做\n4）什么场景\n当前步骤/节点的任务环境是怎样的，包含在哪里做、场景限制。具体可表现为：流入/流出限制（符合条件的数据才能流入或流出）、页面环境（页面关联、字段权限。在哪个页面上操作控制能看到/操作页面的哪些字段）等。\n5）做什么事\n当前步骤/节点的具体任务是什么，或者要执行什么行为。具体可表现为：填表、审批、调用子流程、调用API、发送消息、发送事件等行为。\n6）怎样做\n当前步骤/节点的行为规则。具体可表现为会签规则、自动审批规则、催办规则等。\n封装例子：\n1）业务场景有审批，封装的审批节点就会限定部分元素，不给修改。例如限定分支路径只有通过/拒绝两条、限定审批规则（下拉选择，不能自定义）、限定必须做审批行为（要关联相应审批页面）\n# 5.6 逻辑编排（API/工作流） 对使用者来说，API是封装好函数逻辑的黑匣子，输入入参，得到出参。在aPaaS配置层面，API的本质是一种封装好的满足特定需求的逻辑处理流模块。与流程类似，API也是一种人为规定的有序路径，也有各种要素。主要区别为API是对代码逻辑的可视化，而流程是对业务过程的可视化。\n模块设计：\n逻辑编排是以技术思维抽象程序语法，将其可视化为节点。然后，根据业务场景，抽象分析常用的代码情况，将其可视化为节点。节点包含节点样式（布局、样式）、节点属性配置（主要是节点出入参配置）。同时，为了兼容高代码，也支持代码模式开发。\n逻辑编排的可视化表现形式有多种，目前aPaaS主流可视化形式是类似流程的节点路径图（执行树）。而在传统开发里，时序图是API最常见的可视化建模形式。\n1）可视化代码的基本语法。例如判断、循环、变量定义、捕捉处理异常、请求函数等语法。\n2）可视化常见场景。例如调用DAO层服务、数据结构转换、协议转换、动态SQL、调用脚本等。\n3）连接iPaaS和物料中心。例如调用ipaaS封装的连接器，调用物料中心的插件等。\n4）调试和运维。手动调试、自动调试、引用关系、版本管理、运行日志等功能模块。\n限于篇幅，具体节点的IPO模型就不展开详聊。\n# 5.7 组织架构 平台的组织架构是体现企业的内部组织关系（公司部门等）、外部企业关系（产业链上下游）的数字孪生。\n因此，一个租户里，可以分为内部架构和外部架构。\n内部架构要支持多公司，例如大型集团有总部、子公司和分公司。且多公司之间支持业务协同。\n外部架构里，由于不同租户可能使用不同产品，所以除了要支持同产品的跨租户业务协同，还需要支持不同产品的跨租户协同（主要通过iPaaS）。\n同时，可以在平台的基础属性上，个性化组织架构的附属属性，更符合真实情况。例如，为部门设置专门的个性化属性（如一个部门有多种职责负责人）。\n# 5.8 权限 权限体系是企业精细化管理、数据安全的重要模块。B端产品里，权限与企业规定有关，往往与组织及其角色/身份绑定，也可以直接与用户绑定。\n权限主要有以下3种：\n1）功能权限（菜单权限、页面权限、按钮权限）\n功能权限是前端控制用户能看到哪个菜单、页面、按钮。\n2）数据权限（行权限、列权限、字段权限）\n数据权限是前端控制用户能看到哪些字段/字段数据。行权限和列权限主要针对列表页面，而字段权限主要针对表单页面。\n3）API权限\nAPI权限是后端控制用户能访问哪些API。这是数据权限的加强版，避免用户修改传参，强制调用API导致数据安全问题。\n# 5.9 跨平台 跨平台是指aPaaS能产出web、APP、小程序等终端的应用，且多端支持数据互通。\n主要有两种玩法：\n1）一次配置，多端共用\n以web端配置为主，自动生成移动端的样式。而且需要兼容不同厂商的APP（IOS、Android、鸿蒙）、小程序（钉钉、飞书、企微）。\n移动端主要作为所有微应用和微BI的入口，进入应用内部后，各个模块的功能逻辑与web端一致。\n2）多端各自配置\nweb端、APP、小程序的页面和交互在各自的设计器里配置，但仍然共用后端逻辑。主要适用于移动端对交互要求较高的领域。\n# 5.10 集成和开放（iPaaS） iPaaS的本质是本系统主动或被动地与企业内外的其他系统相互进行数据交流。iPaaS是打通企业内外系统，连接企业全域全价值链场景、解决数据孤岛的重要利器。主要分为集成、开放两部分：\n1）集成\n集成是本系统访问或操作其他系统的数据和功能。基本模块是连接器和集成流。连接器是一个封装了某个库/系统的功能的组件，使用者不需要关心如何对接系统，直接根据业务选择合适操作调用即可。而集成流是可视化的数据逻辑处理流，可以根据场景自动处理跨系统交流任务。\n2）开放\n本系统的API开放给其他系统，允许其他系统访问和操作本系统的数据和功能。除了官方直接通过代码提供开放API（主要是一些系统内置功能，例如组织架构基础信息），也可以与逻辑编排融合，允许用户自定义开放API。相当于把本系统封装成一个连接器，开放给其他租户的同产品，或不同产品。\n模块设计：\n1）连接器\n抽象系统对接的业务场景，可以将连接器拆分为6个模块：基本信息、授权配置、操作配置、调试、文档、运维管理。\n1.1）授权配置。配置授权方式、授权参数等内容。\n1.2）操作配置。管理封装对象所有支持的操作，每个操作都是一个逻辑处理流（可复用逻辑编排功能，也支持代码编程）。例如获取授权出参（如token）、增删改查对接系统的数据、订阅对方系统事件等。\n1.3）调试。测试连接器是否双方都畅通。\n1.4）文档。根据授权和操作模块自动输出对接文档。\n1.5）运维管理。连接器的版本管理、引用关系、日志管理等运维功能。\n同时，为了方便客户快速调用，官方一般需要提前对接好国内各大软件，通过生态市场提供给客户。例如钉钉、飞书、企微、用友、金蝶等软件。\n2）集成流\n集成流可以看做触发器+逻辑编排，区别在于集成流非常适合管理需要在后台长时间运行的任务，而API编排主要管理即时任务。例如从其他系统的数据库里同步数据到本平台就是长任务。\n# 5.11 数据可视化（BI） BI的本质是根据场景，将隐形的原始数据转化成显性的具有参考价值的信息，且以恰当方式展示出来，为不同用户提供数据依据和决策支持。 在aPaaS上的BI有个优势：aPaaS可以集成并统一管理企业全域全价值链的数据，并支持用户灵活自助地使用BI辅助决策。\n模块设计：\n1）数据集成。“输入从哪里来”。通过iPaaS集成本平台、跨平台、跨公司的所有数据源，包含API、数据库（mysql、MongoDB）、静态数据等多种格式的数据源。\n2）数据清洗。“输入限制”，配置规则清洗“脏数据”，得到符合BI输入限制的数据。\n3）可视化配置。“BI处理”。对于整体BI配置，主要处理整个BI图表的输入问题。例如什么时候输入和如何输入，可以通过websocket通道实时输入、或者定时调用API。\n再拆一层，就是各个图元配置的IPO了。例如，输入内容是数据源（本平台模型数据、API、外部平台数据源）和图表要素配置（指标维度、数据权限、动作事件、样式等）。为了更快输入，可以提前为每个模型设计好指标模板，方便直接引用。\n4）使用BI。“输出什么、输出到哪里”。最终输出大屏、看板、组态或传统报表等展示给用户查看，可以独立页面展示或嵌入其他页面展示。\n# 5.12 其他 aPaaS还有很多重要模块，例如物料中心（前后端组件、区块、用户自定义模板等）、RPA、事件、定时任务、打印模板等。但限于篇幅，暂且不表。\n# 6. 浅谈运营 # 6.1 运营方式 目前aPaaS业界内主要有两种运营方式：\n1）纯定制项目+实施团队\n公司组织实施团队，将aPaaS作为公司的开发工具，实施定制项目并交付给客户。这里的aPaaS可以是公司自研或采购的。\n还有一种情况也会采用该方式：公司自研的aPaaS还不足以作为产品推向市场，但为了更快得到落地经验，进而反哺迭代。这种玩法有时也派人到客户那里驻场，根据客户需求随时调整配置。同时，为了减少成本，实施团队会大量雇佣实习生。\n2）订阅制+增值服务\n公司提供不同套餐版本以供客户订阅或私有化部署，然后提供插件市场、模板市场、专家顾问、定制等增值服务。整体玩法与SaaS相似。\n# 6.2 浅谈增长 运营的本质是降低交易成本，提高交易效率。现阶段，对于想单独推向市场的aPaaS，我认为比较适合采用AARRR模型进行用户增长分析。前提是保证产品与市场匹配，否则产品即使到达了客户也会被抛弃。\n1）拉新（Acquisition）：小灯塔\n拉新主要解决拉谁，怎么拉的问题。\n正如上面所说，aPaaS主要面向有数字化转型、升级需求的客户。针对不同层次的用户需要用不同的解决方案和拉新渠道。\n目前拉新最重要的两种渠道是：企业通讯与办公工具（飞书/钉钉/企业微信）引流、客户相互推荐。除此之外招投标、地推、广告也是常见的方式。\n我认为，目前最好的广告是成为国家推荐的样本。国家背书让客户采购选型成本更低：工信部、财政部的“小灯塔”数字化转型样本项目。 两部门关于开展财政支持中小企业数字化转型试点工作的通知\n2）激活（Activation）：免费基础版+专人引导+模板生态\n开箱即用、永久免费的基础版可降低客户的注册成本。\n注册后，为了降低客户初次使用的学习成本和迷茫感，需要帮助客户解决第一个问题，让其迅速体验到数字化的效果。公司可派专人服务引导新客户， 调研客户当前问题，帮助客户寻找和安装合适的应用模板或指导使用，让客户产生第一条数据，完成激活。\n3）留存（Retention）：打铁还需自身硬\n留存关键是aPaaS能真正解决客户问题，有效地实现产品价值。\n4）转化（Revenue）：基础版+按需付费+自主试用\n目前主流的订阅是区分不同套餐，每个套餐包含不同功能和不同基础设施。但我认为，在使用初期，客户不清楚每个功能的作用，也不知道自己未来是否会用到某个功能。如果强行推销高级版套餐，由于客户并不用到某个属性/节点，客户心理可能抵抗采购，也就提高了客户的交易成本。这种玩法非常容易变成价格战。\n我的想法是：类比以前IaaS将硬件基础设施拆分，以及现在serverless热潮，那aPaaS是否可以将功能模块拆分，允许客户按需采购呢？或者直接根据功能使用情况按需付费。例如，客户用不到API的复杂节点，那就不收费。很少使用时，按调用次数收费。如果要频繁使用，允许单独买断功能项。\n同时，我比较赞同简道云的试用玩法，由客户自己决定什么时候领取高级功能使用机会。而不是注册后直接开启高级试用，避免客户连基础版功能都尚未掌握，就被迫浪费高级试用机会。\n5）传播（Referral）：生态化\nB端产品传播在于客户之间的相互推荐。例如某次政府组织的分享会、以及熟人推荐。除了产品自身口碑好，我认为还可以通过生态化让客户进一步主动传播。客户为了进一步提高效率，有概率把产品分享给产业链上下游，以实现跨租户协同处理业务。\n","date":"2022-09-15T20:00:00Z","image":"https://xiuwei.github.io/p/several-thoughts-on-apaas/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_610182_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/several-thoughts-on-apaas/","title":"关于 aPaaS 的几点思考"},{"content":" # 引言 在分布式系统中，多个节点同时访问共享资源可能导致数据一致性和并发控制的问题。分布式锁作为一种常见的解决方案，在这种情况下发挥着重要作用。\n分布式锁是一种用于协调分布式系统中多个节点对共享资源的访问的机制。在分布式系统中，我们通常会遇到多个节点同时访问共享资源的情况，而分布式锁可以确保在任何时刻只有一个节点能够获得对共享资源的访问权。\n# 实现方式 分布式锁的实现可以基于不同的技术和存储介质，包括基于数据库的实现、基于缓存的实现、基于分布式协调服务（如ZooKeeper）的实现等。每种实现方式都有其特点和适用场景，需要根据具体的业务需求和系统架构选择合适的实现方式。\n设计分布式锁的时候，一般要遵循这几个要求：\n互斥 ，有且只有一个进程能拿到锁且解锁的操作只能由加锁的进程执行（A拿到的锁不能让B释放） 超时机制 ，拿到锁的进程必须在规定时间内解锁（不然其他进程会一直阻塞） 机会平等 ，保持其他等待进程获取锁的机会是平等的（先到先得等思路） 可重入 ，同一个进程加的锁可以再次获得或者释放对应的锁 总的来讲，这把锁一定是放在外部存储介质上，根据存储介质的不同，笔者根据自己的实践总结出以下几个方法实现方案：MySQL、Redis、强一致性算法。\n# MySQL 这种方式主要是用到了表的功能，毕竟 MySQL 的核心就是对表的操作嘛。具体的实现方式：\n创建一张表，用以存储锁。设置表中的一列为唯一索引来作为排他性 获取锁时在数据库中添加一条记录 释放锁的时删除添加的那条记录 这是常规的用数据库表来实现分布式锁的步骤，不过很明显有两个严重缺陷：没有超时设置、没有重入。解决超时设置和重入问题也不是不行，代价挺高的。比如：\n用 select **** for update，来解决超时设置问题 用 version 这种乐观锁的方式来解决重入问题 上面的解决方案加重了业务逻辑，况且性能不高（for update 可能会触发表锁等，version 的方式是为每一把锁都建立一张表），还有就是单点故障。所以，这种方案一般不会在生产中使用，这里拿来就是当个比较。\n# Redis 既然 MySQL 的 方式有单点故障、性能等问题，那我们可以使用缓存数据库。最典型的就是 Redis 了。具体实现方式如下：\n用 SETEX key seconds value 命令设置锁（这是个原子命令，seconds 是时间，key 就是锁的名字） 释放锁的时候直接 删除 key 的方式（如果删除操作也要确保原子特性的话，可采用 lua 脚本的方式） 这种实现方式有几个缺陷：\n单点故障。虽然 Redis 有主从方式备份，但是主从方式是异步的。客户端1 在主上加锁成功，但是主挂了。从变成主之后还没来得及同步客户端1 的加锁操作，客户端2 在新的主上又加锁成功。导致两个客户端同时加了锁。 超时异常。客户端1 加锁成功，但是阻塞了。超时后客户端2 又拿到锁。这一个锁下有两个进程（一个阻塞、一个正常）可能引发线程安全问题 时钟漂移。客户端的时间比 redis 的时间晚了，会导致锁提前释放。 有鉴于此，有了个 RedLock 的方案，大体过程如下：\n首先，redis 是多点部署的，不存在主从、集群协调之类，就是实实在在的多个 master 的 redis 进程 客户端获取时间戳。 使用同一个key和具有唯一值的value依次从 redis 的服务器上尝试获取锁（假设这里有 5 台 redis） 因为连接redis 是需要时间的，所以这个 key 的时间应当减去连接 redis 的耗时 当成功获取锁的个数超过 redis 服务器总数的半数以上，即可认为加锁成功（比如5台，获取了3台就算成功） 如果因为某些原因获取失败，对所有 redis 服务器进行删除锁的操作（防止加锁成功但获取响应失败） 总的来说，其实就是讲第一种方案做了个分布式的操作作为保障……但，这个也是有隐患的：\n客户端1 在5 台 redis 服务器上正确获取到了三台（假设 A、B、C、D、E五台，获取到了A、B、C三台），加锁成功，但是C挂了触发了C的主从切换。这与此同时 客户端2 又在 C、D、E 获取锁成功。 网络连接的耗时决定了锁的有效时间 所以，任何一种方案都有缺陷和优点，看取舍了。选择了 redis 作为分布式锁，就是看中了其性能好的方面。但是终归不是强一致性的方案。需要在业务层面保障了，比如设置幂等操作等。\n# 强一致性算法 Redis 的分布式锁方案最根本的隐患总结一句话就是存储锁的这个状态在节点之间（主从之间）并不能达成强一致。自然而然的就能想到基于强一致性算法的实现。这里以 etcd 为例谈谈实践方式。\n首先 etcd 是一个基于 KEY-VALUE 的分布式一致性的存储系统，主要用来服务发现和共享配置。这里我们利用的就是利用 KEY-VALUE 的建立、获取来实现分布式锁。\n利用 etcd 的 prefix 机制，让多个抢锁的进程（也就是 etcd 的客户端了）建立前缀相同、名称不同的 key。通过比较每个 key 的 revison 的大小来决定哪个先抢到的锁 利用 etcd 的 lease 机制设置 key 的超时时间。当然，这个 key 可以续约 利用 etcd 的 watch 机制来监听锁的释放 上述是常规的用 etcd 机制实现分布式锁的方案，其实 etcd 很贴心的为我们提供了一个叫 concurrency 的包来给我们是用，原理上就是对上述的业务逻辑进行了封装，拿来用即可。\n# 方案选择 上述几个方案在不同的业务需求下可以有不同的选择，在选择的时候考虑的无非就是从性能、可用方面去考虑。那我们这里针对几种方案进行对比。\n# 权衡利弊 针对性能、可用性方面的总结如下：\nMySQL 方式性能低、可用性差，几乎不作为生产的选择，一般作为分布式锁的入门理解 Redis 方式性能高，但有状态不一致的隐患。如果生产上可以配置一些幂等操作的辅助，但代码复杂度就高了 强一致性算法方式性能比 Redis 低，但因为基于状态强一致性算法的原因，其可用性高。 所以，追求高性能场景，可以选取 Redis 方式。追求高可用的场景，选取强一致性算法方式。\n# 思考 一般情况下，系统的可用性越高，其性能就越低。因为可用性方面我们需要考虑的地方就多了，必然带来一定的复杂度，其性能必然下降。\n分布式锁作为一个基础组建，个人认为应该更关心的是可用性方面，毕竟都用到锁了，那说明资源的竞态已经是重中之重，能提高可用性就尽量提高。所以，生产上个人倾向于强一致性方面的实现，比如 etcd 或者 zookeeper 方式等。\n# 参考资料 Distributed Locks with Redis etcd concurrency Design distributed lock with MySQL\n","date":"2022-08-04T21:00:00Z","image":"https://xiuwei.github.io/p/exploring-distributed-locks/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_2780424_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/exploring-distributed-locks/","title":"探索分布式锁：实践记录与经验分享"},{"content":" # 1.概述 Java Flow API 是在 Java 9 中作为 Reactive Stream 规范的实现引入的。\n在这篇文章里，我们首先介绍响应式流，然后介绍它与RxJava和Flow API的关系。\n# 2.什么是 Reactive Stream Reactive Manifesto 引入了 Reactive Streams 来指定具有非阻塞背压的异步流处理的标准。\nReactive Stream 规范的范围是定义一组最小的接口来实现这些目标：\norg.reactivestreams.Publisher 是一个数据提供者，根据订阅者的需求向订阅者发布数据 org.reactivestreams.Subscriber 是数据的消费者——订阅发布者后可以接收数据 org.reactivestreams.Subscription 当发布者接受订阅者时创建 org.reactivestreams.Processor 既是订阅者又是发布者 - 它订阅发布者，处理数据，然后将处理后的数据传递给订阅者 Flow API源自规范，RxJava早于它，但从2.0开始，RxJava也支持该规范。\n我们将深入探讨两者，但首先，让我们看一个实际用例。\n# 3.用例 在本教程中，我们使用直播视频服务作为我们的用例。与点播视频流相反，直播视频流不依赖于消费者。因此，服务器以自己的速度发布流，而适应是消费者的责任。\n在最简单的形式中，我们的模型由一个视频流发布者和一个作为订阅者的视频播放器组成。\n让我们实现VideoFrame作为我们的数据项：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 public class VideoFrame { /** * 编号 */ private long number; /** * 视频数据 */ private byte[] data; public VideoFrame(long number, byte[] data) { this.number = number; this.data = data; } public VideoFrame(long number) { this.number = number; } public VideoFrame() { } public long getNumber() { return number; } public void setNumber(long number) { this.number = number; } public byte[] getData() { return data; } public void setData(byte[] data) { this.data = data; } } # 4.Flow API 的实现 JDK 9 中的 Flow API 对应于 Reactive Streams 规范。使用 Flow API，如果应用程序最初请求 N 个项目，则发布者最多将 N 个项目推送给订阅者。\nFlow API 接口均位于 java.util.concurrent.Flow 接口中。它们在语义上等同于各自的响应式流。\n让我们将 VideoStreamServer 作为 VideoFrame 的发布者。\n1 2 3 4 5 6 public class VideoStreamServer extends SubmissionPublisher\u0026lt;VideoFrame\u0026gt; { public VideoStreamServer() { super(Executors.newSingleThreadExecutor(),5); } } 我们从 SubmissionPublisher 扩展了 VideoStreamServer ，而不是直接实现 Flow::Publisher。 SubmissionPublisher 是 Fl​​ow::Publisher 的 JDK 实现，用于与订阅者进行异步通信，因此它让我们的 VideoStreamServer 按照自己的速度发送。\n此外，它对于背压和缓冲区处理也很有帮助，因为当调用 SubmissionPublisher::subscribe 时，它​​会创建 BufferedSubscription 的实例，然后将新订阅添加到其订阅链中。 BufferedSubscription 可以缓冲已发布的项目，最高可达 SubmissionPublisher#maxBufferCapacity。\n现在让我们定义 VideoPlayer，它消耗 VideoFrame 流。因此它必须实现 Flow::Subscriber。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class VideoPlayer implements Flow.Subscriber\u0026lt;VideoFrame\u0026gt;{ Flow.Subscription subscription = null; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(VideoFrame item) { System.out.println(\u0026#34;播放 ： \u0026#34;+item.getNumber()); subscription.request(1); } @Override public void onError(Throwable throwable) { throwable.printStackTrace(); } @Override public void onComplete() { System.out.println(\u0026#34;播放完了！\u0026#34;); } } VideoPlayer 订阅 VideoStreamServer ，订阅成功后调用 VideoPlayer::onSubscribe方法，请求一帧。 VideoPlayer::onNext 接收帧并请求新帧。请求的帧的数量取决于用例和订阅者实现。\n最后，我们把直播场景串起来：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 try (VideoStreamServer streamServer = new VideoStreamServer()) { streamServer.subscribe(new VideoPlayer()); ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1); AtomicLong frameNumber = new AtomicLong(); executorService.scheduleAtFixedRate(() -\u0026gt; { streamServer.offer(new VideoFrame(frameNumber.incrementAndGet()),(subscriber, videoFrame) -\u0026gt; { subscriber.onError(new RuntimeException(\u0026#34;Frame#： \u0026#34; + videoFrame.getNumber() + \u0026#34; 因触发背压被丢弃！\u0026#34;)); return true; }); }, 0, 1, TimeUnit.MILLISECONDS); Thread.sleep(3000); } catch (Exception e) { throw new RuntimeException(e); } # 5.使用 RxJava 实现 RxJava 是 ReactiveX 的 Java 实现。 ReactiveX（或 Reactive Extensions）项目旨在提供反应式编程概念。它是观察者模式、迭代器模式和函数式编程的组合。\nRxJava 的最新版本是 3.x。 RxJava 从 2.x 版本开始就支持 Reactive Streams 及其 Flowable 基类，但它比 Reactive Streams 更重要，它有几个基类，如 Flowable、Observable、Single、Completable。\nFlowable 从 Reactive Streams 扩展了 Publisher。因此，许多 RxJava 运算符直接接受 Publisher 并允许与其他 Reactive Streams 实现直接互操作。\n首先，创建一个无限延迟流的视频流生成器：\n1 2 3 Stream\u0026lt;VideoFrame\u0026gt; videoStream = Stream.iterate(new VideoFrame(0), videoFrame -\u0026gt; { return new VideoFrame(videoFrame.getNumber() + 1); }); 然后我们定义一个 Flowable 实例来在单独的线程上生成帧：\n1 2 3 Flowable .fromStream(videoStream) .subscribeOn(Schedulers.from(Executors.newSingleThreadExecutor())) 需要注意的是，无限流对我们来说已经足够了，但是如果我们需要更灵活的方式来生成流，那么 Flowable.create 是一个不错的选择。\n1 2 3 4 5 6 7 8 9 10 11 Flowable .create(new FlowableOnSubscribe\u0026lt;VideoFrame\u0026gt;() { AtomicLong frame = new AtomicLong(); @Override public void subscribe(@NonNull FlowableEmitter\u0026lt;VideoFrame\u0026gt; emitter) { while (true) { emitter.onNext(new VideoFrame(frame.incrementAndGet())); //sleep for 1 ms to simualte delay } } }, /* Set Backpressure Strategy Here */) 然后，在下一步中，VideoPlayer 订阅此 Flowable 并观察单独线程上的项目。\n1 2 3 4 5 6 videoFlowable .observeOn(Schedulers.from(Executors.newSingleThreadExecutor())) .subscribe(item -\u0026gt; { log.info(\u0026#34;play #\u0026#34; + item.getNumber()); // sleep for 30 ms to simualate frame display }); 最后，我们将配置背压策略。如果我们想在帧丢失的情况下停止视频，因此我们必须在缓冲区已满时使用 BackPressureOverflowStrategy::ERROR。\n1 2 3 4 5 6 7 8 9 Flowable .fromStream(videoStream) .subscribeOn(Schedulers.from(Executors.newSingleThreadExecutor())) .onBackpressureBuffer(5, null, BackpressureOverflowStrategy.ERROR) .observeOn(Schedulers.from(Executors.newSingleThreadExecutor())) .subscribe(item -\u0026gt; { log.info(\u0026#34;play #\u0026#34; + item.getNumber()); // sleep for 30 ms to simualate frame display }); # 6.RxJava 和 Flow API 的比较 即使在这两个简单的实现中，我们也可以看到 RxJava 的 API 是多么丰富，特别是在缓冲区管理、错误处理和反压策略方面。它以其流畅的 API 为我们提供了更多的选择和更少的代码行。现在让我们考虑更复杂的情况。\n假设我们的播放器在没有编解码器的情况下无法显示视频帧。因此，对于 Flow API，我们需要实现一个处理器来模拟编解码器并位于服务器和播放器之间。使用 RxJava，我们可以使用 Flowable::flatMap 或 Flowable::map 来完成。\n或者让我们想象一下，我们的播放器还将播放实时翻译音频，因此我们必须合并来自不同发布商的视频和音频流。有了RxJava，我们可以使用Flowable::combineLatest，但是有了Flow API，这并不是一件容易的事。\n尽管如此，可以编写一个自定义处理器来订阅两个流并将组合数据发送到我们的视频播放器。然而，实施起来却很令人头疼。\n# 7.为什么使用 Flow API？ 说到这里，我们可能会有一个疑问，Flow API 背后的理念是什么？\n如果我们在JDK中搜索Flow API的用法，我们可以在java.net.http和jdk.internal.net.http中找到一些东西。\n此外，我们可以在reactor项目或 reactive stream 包中找到适配器。例如，org.reactivestreams.FlowAdapters 具有将 Flow API 接口转换为 Reactive Stream 接口的方法，反之亦然。因此，它有助于 Flow API 和具有反应式流支持的库之间的互操作性。\n所有这些事实都有助于我们理解 Flow API 的目的：它被创建为 JDK 中的一组反应式规范接口，无需依赖第三方。 此外，Java 期望 Flow API 被接受为反应式规范的标准接口，并在 JDK 或其他为中间件和实用程序实现反应式规范的基于 Java 的库中使用。\n# 参考资料 原文链接 示例源码 ","date":"2021-12-12T18:00:00Z","image":"https://xiuwei.github.io/p/rxjava-vs-java-flow/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_4206946_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/rxjava-vs-java-flow/","title":"RxJava API 与 Java 9 Flow API 的区别"},{"content":" # 1.概述 在本文中，我们将研究 Java 9 反应式流。简而言之，我们将能够使用 Flow 类，它包含用于构建反应式流处理逻辑的主要构建块。\nReactive Streams 是具有非阻塞背压的异步流处理标准。该规范在 Reactive Manifesto 中定义，并且有多种实现，例如 RxJava 或 Akka-Streams。\n# 2.Reactive API 概览 为了构建 Flow ，我们可以使用三个主要抽象并将它们组合成异步处理逻辑。\n每个 Flow 都需要处理 Publisher 实例向其发布的事件； Publisher 有一种方法——subscribe()。\n消息的接收者需要实现 Subscriber 接口。 通常，这是每个流处理的结束，因为它的实例不会进一步发送消息。 我们可以将Subscriber 视为一个接收器。它有四个需要重写的方法 - onSubscribe()、onNext()、onError() 和 onComplete()。我们将在下一节中讨论这些内容。\n如果我们想转换传入的消息并将其进一步传递给下一个Subscriber，我们需要实现 Processor 接口。 它既充当 Subscriber ，因为它接收消息，又充当 Publisher ，因为它处理这些消息并将其发送以进行进一步处理。\n# 3.发布和消费消息 假设我们要创建一个简单的 Flow，其中一个发布消息的 Publisher 和一个简单的 Subscriber 在消息到达时消费消息 - 一次一个。\n让我们创建一个 EndSubscriber 类。我们需要实现 Subscriber 接口。接下来，我们将重写所需方法。\nonSubscribe() 方法在处理开始之前调用。Subscription (订阅)的实例作为参数传递。它是一个用于控制 Subscriber 和 Publisher 之间的消息流的类：\n1 2 3 4 5 6 7 8 9 10 11 public class MySubscriber\u0026lt;T\u0026gt; implements Flow.Subscriber\u0026lt;T\u0026gt; { private Flow.Subscription subscription; public List\u0026lt;T\u0026gt; consumedElements = new ArrayList\u0026lt;\u0026gt;(); @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } } 我们还初始化了一个空的 ConsumerElements 列表，它将在测试中使用。\n现在，我们需要实现 Subscriber 接口的其余方法。这里的主要方法是 onNext() – 每当 Publisher 发布新消息时都会调用该方法：\n1 2 3 4 5 6 @Override public void onNext(T item) { System.out.println(\u0026#34;接收到数据 ： \u0026#34;+item); consumedElements.add(item); subscription.request(1); } 请注意，当我们在 onSubscribe() 方法中启动订阅并处理消息时，我们需要调用订阅上的 request() 方法来表明当前 Subscriber 已准备好消费更多消息。\n最后，我们需要实现 onError() ——每当处理过程中抛出异常时就会调用它，以及 onComplete() ——当 Publisher 关闭时调用：\n1 2 3 4 5 6 7 8 9 @Override public void onError(Throwable throwable) { throwable.printStackTrace(); } @Override public void onComplete() { System.out.println(\u0026#34;MySubscriber Complete!\u0026#34;); } 让我们为处理流程编写一个测试。我们将使用 SubmissionPublisher 类——一个来自 java.util.concurrent 的构造——它实现了 Publisher 接口。\n我们将向 Publisher 提交 N 个元素——我们的最终 Subscriber 将收到这些元素：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Test public void whenSubscribeToIt_thenShouldConsumeAll() throws InterruptedException { SubmissionPublisher\u0026lt;String\u0026gt; publisher = new SubmissionPublisher\u0026lt;\u0026gt;(); MySubscriber\u0026lt;String\u0026gt; subscriber = new MySubscriber\u0026lt;\u0026gt;(); publisher.subscribe(subscriber); List\u0026lt;String\u0026gt; items = List.of(\u0026#34;1\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;x\u0026#34;); assertEquals(1, publisher.getNumberOfSubscribers()); items.forEach(publisher::submit); publisher.close(); await().atMost(1000, TimeUnit.MILLISECONDS) .until( () -\u0026gt; subscriber.consumedElements.size() == items.size() ); } 请注意，我们正在 EndSubscriber 实例上调用 close() 方法。它将在给定Publisher 的每个 Subscriber 上调用下面的 onComplete() 回调。\n运行该程序将产生以下输出：\n1 2 3 4 5 6 7 接收到数据 ： 1 接收到数据 ： x 接收到数据 ： 2 接收到数据 ： x 接收到数据 ： 3 接收到数据 ： x MySubscriber Complete! # 4.消息的转换 假设我们想要在 Publisher 和 Subscriber 之间构建类似的逻辑，但也应用一些消息转换。\n我们将创建实现 Processor 并扩展 SubmissionPublisher 的 TransformProcessor 类 - 这将同时是 Publisher 和 Subscriber。\n我们将传入一个将输入转换为输出的 Function（函数）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class TransformProcessor\u0026lt;T, R\u0026gt; extends SubmissionPublisher\u0026lt;R\u0026gt; implements Flow.Processor\u0026lt;T, R\u0026gt; { private final Function\u0026lt;T, R\u0026gt; function; private Flow.Subscription subscription; public TransformProcessor(Function\u0026lt;T, R\u0026gt; function) { super(); this.function = function; } @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(T item) { submit(function.apply(item)); subscription.request(1); } @Override public void onError(Throwable t) { t.printStackTrace(); } @Override public void onComplete() { close(); } } 我们快速编写一个将 Publisher 发送的 String 元素转换为 Integer 元素的单元测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Test public void whenSubscribeAndTransformElements_thenShouldConsumeAll() throws InterruptedException { SubmissionPublisher\u0026lt;String\u0026gt; publisher = new SubmissionPublisher\u0026lt;\u0026gt;(); TransformProcessor\u0026lt;String, Integer\u0026gt; transformProcessor = new TransformProcessor\u0026lt;\u0026gt;(Integer::parseInt); MySubscriber\u0026lt;Integer\u0026gt; subscriber = new MySubscriber\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; items = List.of(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;); List\u0026lt;Integer\u0026gt; expectedResult = List.of(1, 2, 3); publisher.subscribe(transformProcessor); transformProcessor.subscribe(subscriber); items.forEach(publisher::submit); publisher.close(); await().atMost(1000, TimeUnit.MILLISECONDS) .until(() -\u0026gt;{ assertIterableEquals(expectedResult, subscriber.consumedElements); return subscriber.consumedElements.size() == expectedResult.size(); } ); } 请注意，调用基础 Publisher 上的 close() 方法将导致调用 TransformProcessor 上的 onComplete() 方法。\n请记住，处理链中的所有 Publisher 都需要以这种方式关闭。\n# 5.使用 Subscription 控制消息取值 假设我们只想使用 Subscription 中的第一个元素，应用一些逻辑并完成处理。我们可以使用 request() 方法来实现这一点。\n让我们修改 MySubscriber 以仅消耗 N 条消息。我们将该数字作为 howMuchMessagesConsume 的构造函数参数进行传递：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class MySubscriber\u0026lt;T\u0026gt; implements Flow.Subscriber\u0026lt;T\u0026gt; { private Flow.Subscription subscription; private final AtomicInteger howMuchMessagesConsume; public List\u0026lt;T\u0026gt; consumedElements = new ArrayList\u0026lt;\u0026gt;(); public MySubscriber(Integer howMuchMessagesConsume) { this.howMuchMessagesConsume = new AtomicInteger(howMuchMessagesConsume); } @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(T item) { howMuchMessagesConsume.decrementAndGet(); System.out.println(\u0026#34;接收到数据 ： \u0026#34;+item); if (howMuchMessagesConsume.get() == 0) { consumedElements.add(item); subscription.request(1); } } @Override public void onError(Throwable throwable) { throwable.printStackTrace(); } @Override public void onComplete() { System.out.println(\u0026#34;MySubscriber Complete!\u0026#34;); } } 编写单元测试，实现只使用 Subscription 中的第一个元素：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Test public void whenRequestForOnlyOneElement_thenShouldConsumeOne() throws InterruptedException { SubmissionPublisher\u0026lt;String\u0026gt; publisher = new SubmissionPublisher\u0026lt;\u0026gt;(); MySubscriber\u0026lt;String\u0026gt; subscriber = new MySubscriber\u0026lt;\u0026gt;(1); publisher.subscribe(subscriber); List\u0026lt;String\u0026gt; items = List.of(\u0026#34;1\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;x\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;x\u0026#34;); List\u0026lt;String\u0026gt; expected = List.of(\u0026#34;1\u0026#34;); assertEquals(1, publisher.getNumberOfSubscribers()); items.forEach(publisher::submit); publisher.close(); await().atMost(1000, TimeUnit.MILLISECONDS) .until(() -\u0026gt; { assertIterableEquals(expected, subscriber.consumedElements); return expected.size() == subscriber.consumedElements.size(); } ); } 尽管 Publisher 正在发布六个元素，但我们的 MySubscriber 将仅消耗一个元素，因为它发出只处理该单个元素的信号。\n通过在 Subscriber 上使用 request() 方法，我们可以实现更复杂的背压（back-pressure）机制来控制消息消费的速度。\n","date":"2021-12-12T12:00:00Z","image":"https://xiuwei.github.io/p/java-9-reactive-streams/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_1105727_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/java-9-reactive-streams/","title":"Java 9 Reactive Streams"},{"content":" # 1. 概述 java.util.function 包是 Java 8 引入的一个包，其中包含了一组函数式接口，用于支持函数式编程和Lambda表达式。\n这些函数式接口提供了一种方便的方式来定义和使用函数，可以在很多场景下简化代码的编写和处理。\n# 2. @FunctionalInterface 是什么鬼？ @FunctionalInterface是一个Java注解，用于声明一个接口是函数式接口。函数式接口是指只包含一个抽象方法的接口，用于表示一个函数类型。\n@FunctionalInterface注解的作用是强制编译器检查被注解的接口是否满足函数式接口的条件，即只包含一个抽象方法。如果接口不满足这个条件，编译器会报错。\n函数式接口和@FunctionalInterface的使用场景是在函数式编程中，特别是在使用Lambda表达式时。Lambda表达式允许我们以更简洁的方式定义匿名函数，并将其作为参数传递给其他方法或函数式接口。函数式接口提供了一种标准化的方式来定义和使用这些可传递的函数。\n下面是一个示例，演示了@FunctionalInterface的用途和示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @FunctionalInterface interface Calculator { int calculate(int a, int b); } public class FunctionalInterfaceExample { public static void main(String[] args) { Calculator addition = (a, b) -\u0026gt; a + b; int result = addition.calculate(5, 3); System.out.println(result); // 输出8 Calculator subtraction = (a, b) -\u0026gt; a - b; result = subtraction.calculate(10, 4); System.out.println(result); // 输出6 } } # 3. java.util.function 包接口清单介绍 java.util.function 包下的接口都有 @FunctionalInterface 注解。\n以下表格是 java.util.function 包下所有接口的用途。\n类 描述 Function \u0026lt;T,R\u0026gt; 表示接受一个参数并产生结果的函数。 Predicate \u0026lt;T\u0026gt; 表示一个参数的谓词（boolean函数）。 Consumer \u0026lt;T\u0026gt; 表示接受单个输入参数且不返回任何结果的操作。 Supplier \u0026lt;T\u0026gt; 代表结果的提供者。 UnaryOperator \u0026lt;T\u0026gt; 表示对单个操作数的操作，该操作产生与其操作数类型相同的结果。 BiConsumer \u0026lt;T,U\u0026gt; 表示接受两个输入参数且不返回任何结果的操作。 BiFunction \u0026lt;T,U,R\u0026gt; 表示接受两个参数并产生结果的函数。 BinaryOperator \u0026lt;T\u0026gt; 表示对两个相同类型的操作数的操作，产生与操作数相同类型的结果。 BiPredicate \u0026lt;T,U\u0026gt; 表示两个参数的断言（boolean函数）。 BooleanSupplier 代表 boolean 值结果的供应商。 DoubleBinaryOperator 表示对两个 double 值操作数并产生 double 值结果的操作。 DoubleConsumer 表示接受单个 double 值参数且不返回任何结果的操作。 DoubleFunction 表示接受双值参数并产生结果的函数。 DoublePredicate 表示一个 double 值参数的断言（boolean函数）。 DoubleSupplier 代表 double 值结果的供应商。 DoubleToIntFunction 表示接受双值参数并生成 int 值结果的函数。 DoubleToLongFunction 表示接受双值参数并产生 long 值结果的函数。 DoubleUnaryOperator 表示对产生 double 值结果的单个 double 值操作数的操作。 IntBinaryOperator 表示对两个 int 值操作数并产生 int 值结果的操作。 IntConsumer 表示接受单个 int 值参数且不返回任何结果的操作。 IntFunction 表示接受 int 值参数并产生结果的函数。 IntPredicate 表示一个 int 值参数的谓词（boolean函数）。 IntSupplier 代表 int 值结果的供应商。 IntToDoubleFunction 表示接受 int 值参数并生成双值结果的函数。 IntToLongFunction 表示接受 int 值参数并产生 long 值结果的函数。 IntUnaryOperator 表示对产生 int 值结果的单个 int 值操作数的操作。 LongBinaryOperator 表示对两个 long 值操作数并产生 long 值结果的操作。 LongConsumer 表示接受单个 long 值参数且不返回任何结果的操作。 LongFunction 表示接受 long 值参数并产生结果的函数。 LongPredicate 表示一个 long 值参数的断言（boolean函数）。 LongSupplier 代表 long 值结果的供应商。 LongToDoubleFunction 表示接受 long 值参数并产生双值结果的函数。 LongToIntFunction 表示接受 long 值参数并生成 int 值结果的函数。 LongUnaryOperator 表示对产生 long 值结果的单个 long 值操作数的操作。 ObjDoubleConsumer \u0026lt;T\u0026gt; 表示接受对象值和 double 值参数的操作，并且不返回任何结果。 ObjIntConsumer \u0026lt;T\u0026gt; 表示接受对象值和 int 值参数并且不返回任何结果的操作。 ObjLongConsumer \u0026lt;T\u0026gt; 表示接受对象值和 long 值参数并且不返回任何结果的操作。 ToDoubleBiFunction \u0026lt;T,U\u0026gt; 表示接受两个参数并产生双值结果的函数。 ToDoubleFunction \u0026lt;T\u0026gt; 表示产生双值结果的函数。 ToIntBiFunction \u0026lt;T,U\u0026gt; 表示接受两个参数并生成 int 值结果的函数。 ToIntFunction \u0026lt;T\u0026gt; 表示生成 int 值结果的函数。 ToLongBiFunction \u0026lt;T,U\u0026gt; 表示接受两个参数并产生 long结果的函数。 ToLongFunction \u0026lt;T\u0026gt; 表示产生 long 值结果的函数。 # 4. 常用的函数式接口及其用途 Function\u0026lt;T, R\u0026gt;\n用途：接受一个输入参数并返回一个结果，用于实现将一个类型的值转换为另一个类型的值的操作。 示例代码： 1 2 Function\u0026lt;Integer, String\u0026gt; intToString = (num) -\u0026gt; Integer.toString(num); String str = intToString.apply(42); // 结果为\u0026#34;42\u0026#34; 除了apply方法，Function接口还提供了一些默认方法，用于支持函数的组合、转换和处理。下面是Function接口的所有方法的详细介绍和代码示例： default Function\u0026lt;T, V\u0026gt; andThen(Function\u0026lt;? super R, ? extends V\u0026gt; after) 用途：返回一个组合函数，首先将当前函数的结果传递给参数after的apply方法，然后将该结果作为组合函数的输出结果。 示例代码： 1 2 3 Function\u0026lt;Integer, Integer\u0026gt; square = (num) -\u0026gt; num * num; Function\u0026lt;Integer, String\u0026gt; squareAndToString = square.andThen(Object::toString); String result = squareAndToString.apply(5); // 结果为\u0026#34;25\u0026#34; default Function\u0026lt;V, R\u0026gt; compose(Function\u0026lt;? super V, ? extends T\u0026gt; before) 用途：返回一个组合函数，首先将参数before的结果传递给当前函数的apply方法，然后将该结果作为组合函数的输入参数。 示例代码： 1 2 3 4 Function\u0026lt;Integer, Integer\u0026gt; multiplyBy2 = (num) -\u0026gt; num * 2; Function\u0026lt;Integer, Integer\u0026gt; subtractBy3 = (num) -\u0026gt; num - 3; Function\u0026lt;Integer, Integer\u0026gt; multiplyBy2AndSubtractBy3 = multiplyBy2.compose(subtractBy3); int result = multiplyBy2AndSubtractBy3.apply(5); // 结果为4 default Function\u0026lt;T, T\u0026gt; identity() 用途：返回一个函数，该函数对输入参数执行恒等转换，即返回输入参数本身。 示例代码： 1 2 Function\u0026lt;String, String\u0026gt; identityFunction = Function.identity(); String result = identityFunction.apply(\u0026#34;Hello\u0026#34;); // 结果为\u0026#34;Hello\u0026#34; Predicate\u0026lt;T\u0026gt;\n用途：接受一个输入参数并返回一个布尔值，用于实现条件判断。 示例代码： 1 2 Predicate\u0026lt;Integer\u0026gt; isEven = (num) -\u0026gt; num % 2 == 0; boolean result = isEven.test(5); // 结果为false Consumer\u0026lt;T\u0026gt;\n用途：接受一个输入参数，但不返回任何结果，用于实现对输入参数的操作。 示例代码： 1 2 Consumer\u0026lt;String\u0026gt; printMessage = (message) -\u0026gt; System.out.println(message); printMessage.accept(\u0026#34;Hello, World!\u0026#34;); // 输出\u0026#34;Hello, World!\u0026#34; Supplier\u0026lt;T\u0026gt;\n用途：不接受任何输入参数，但返回一个结果，用于实现对结果的生成。 示例代码： 1 2 Supplier\u0026lt;Double\u0026gt; getRandomNumber = () -\u0026gt; Math.random(); double number = getRandomNumber.get(); // 返回一个随机数 UnaryOperator\u0026lt;T\u0026gt;\n用途：接受一个输入参数，并返回与输入参数类型相同的结果，用于实现对输入参数的操作并返回结果。 示例代码： 1 2 UnaryOperator\u0026lt;Integer\u0026gt; square = (num) -\u0026gt; num * num; int result = square.apply(5); // 结果为25 这只是java.util.function包中的一小部分函数式接口，还有其他一些接口如BiFunction、BiPredicate、BiConsumer等，用于处理两个输入参数的场景。\n这些函数式接口在函数式编程和Lambda表达式中起到了重要的作用，简化了代码的编写，提高了代码的可读性和可维护性。\n","date":"2020-12-18T19:00:00Z","image":"https://xiuwei.github.io/p/java-8-functional/cover_hu5459c0360c2b0cb7a147d2df0eb350ca_1307901_120x120_fill_q75_box_smart1.jpg","permalink":"https://xiuwei.github.io/p/java-8-functional/","title":"Java 8 函数式接口初识"}]